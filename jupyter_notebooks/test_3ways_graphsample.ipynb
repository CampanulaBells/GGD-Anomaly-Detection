{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "import dgl\n",
    "from model import Model\n",
    "from utils import *\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import random\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy.io as sio\n",
    "import datetime\n",
    "from gcn import GCN\n",
    "from typing import List\n",
    "\n",
    "from dgl.nn.pytorch import SGConv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.cuda = True\n",
    "        \n",
    "        self.dataset = \"cora\"\n",
    "        self.device = \"cuda:0\"\n",
    "        self.embedding_dim = 64\n",
    "        \n",
    "        self.n_ggd_epochs = 600\n",
    "        self.patience = 500\n",
    "        self.batch_size = 300\n",
    "        self.eval_freq = 1\n",
    "        \n",
    "        self.n_hidden = 256\n",
    "        self.n_layers = 1\n",
    "        self.dropout = 0\n",
    "        self.proj_layers = 0\n",
    "        self.gnn_encoder = 'gcn'\n",
    "        self.num_hop = 10\n",
    "        self.ggd_lr = 1e-3\n",
    "        self.weight_decay = 0.\n",
    "        \n",
    "        self.subgraph_size = 4\n",
    "        self.auc_test_rounds = 64\n",
    "        \n",
    "        self.neg_batch_size = 1024\n",
    "args =  Args()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def aug_feature_dropout(input_feat, drop_percent=0.2):\n",
    "    # aug_input_feat = copy.deepcopy((input_feat.squeeze(0)))\n",
    "    aug_input_feat = copy.deepcopy(input_feat)\n",
    "    drop_feat_num = int(aug_input_feat.shape[1] * drop_percent)\n",
    "    drop_idx = random.sample([i for i in range(aug_input_feat.shape[1])], drop_feat_num)\n",
    "    aug_input_feat[:, drop_idx] = 0\n",
    "    \n",
    "    return aug_input_feat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Dataset: cora\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print('Dataset: {}'.format(args.dataset), flush=True)\n",
    "device = torch.device(args.device if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "batch_size = args.batch_size\n",
    "\n",
    "adj, features, labels, idx_train, idx_val, idx_test, ano_label, str_ano_label, attr_ano_label = load_mat(args.dataset)\n",
    "\n",
    "features, _ = preprocess_features(features)\n",
    "src, dst = np.nonzero(adj)\n",
    "g = dgl.graph((src, dst))\n",
    "g = dgl.add_self_loop(g)\n",
    "\n",
    "g.ndata['feat'] = torch.FloatTensor(features)\n",
    "g.ndata['label'] = torch.LongTensor(labels)\n",
    "n_edges = g.number_of_edges()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "nb_nodes = features.shape[0]\n",
    "ft_size = features.shape[1]\n",
    "nb_classes = labels.shape[1]\n",
    "\n",
    "# adj = normalize_adj(adj)\n",
    "# adj = (adj + sp.eye(adj.shape[0])).todense()\n",
    "# adj = torch.FloatTensor(adj[np.newaxis]).to(device)\n",
    "\n",
    "features = torch.FloatTensor(features).to(device)\n",
    "labels = torch.FloatTensor(labels).to(device)\n",
    "idx_train = torch.LongTensor(idx_train).to(device)\n",
    "idx_val = torch.LongTensor(idx_val).to(device)\n",
    "idx_test = torch.LongTensor(idx_test).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create GGD model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "gamma = 0.07\n",
      "0 0.8683398488402397\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:23<00:00, 25.36it/s, loss=0.349]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_hidden):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.bilinear = nn.Bilinear(n_hidden, n_hidden, 1)\n",
    "        for m in self.modules():\n",
    "            self.weights_init(m)\n",
    "\n",
    "    def weights_init(self, m):\n",
    "        if isinstance(m, nn.Bilinear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, features, summary):\n",
    "        s = self.bilinear(features, summary)\n",
    "        return s\n",
    "\n",
    "# class DiscriminatorCos(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(DiscriminatorCos, self).__init__()\n",
    "#         self.cos = torch.nn.CosineSimilarity(dim=1, eps=1e-06)\n",
    "# \n",
    "#     def forward(self, features, summary):\n",
    "#         print(features.shape)\n",
    "#         print(summary.shape)\n",
    "#         s = self.cos(features, summary)\n",
    "#         \n",
    "#         return torch.unsqueeze(s, 0)\n",
    "    \n",
    "\n",
    "class GraphSampler(torch.nn.Module):\n",
    "    def __init__(self, graph, n_nodes=4):\n",
    "        super(GraphSampler, self).__init__()\n",
    "        self.g = graph\n",
    "        \n",
    "        indices_list = []\n",
    "        probs_list = []\n",
    "        \n",
    "        A = self.g.adjacency_matrix()\n",
    "        for i in range(self.g.num_nodes()):\n",
    "            row = A[i]._indices()\n",
    "            size = row.size()[1]\n",
    "            tensor_ones = torch.ones(size)\n",
    "            indices = torch.cat([tensor_ones.unsqueeze(0) * i, row], dim=0)\n",
    "            indices_list.append(indices)\n",
    "            if size < n_nodes: \n",
    "                probs_list.append(tensor_ones)\n",
    "            else:\n",
    "                dropout_prob = n_nodes / size\n",
    "                probs_list.append(tensor_ones * dropout_prob)\n",
    "        probs = torch.cat(probs_list)\n",
    "        self.sampler = torch.distributions.bernoulli.Bernoulli(probs=probs.to(self.g.device))\n",
    "        self.indices = torch.cat(indices_list, dim=1).to(torch.int32).to(self.g.device)\n",
    "        \n",
    "    def sample(self):\n",
    "        new_indices = torch.masked_select(\n",
    "            self.indices, \n",
    "            self.sampler.sample().to(torch.bool)\n",
    "        ).reshape((2, -1))\n",
    "        graph = dgl.graph((new_indices[0, :], new_indices[1, :]), num_nodes= self.g.num_nodes())\n",
    "        if 'feat' in self.g.ndata:\n",
    "            graph.ndata['feat'] = self.g.ndata['feat']\n",
    "        if 'label' in self.g.ndata:\n",
    "            graph.ndata['label'] = self.g.ndata['label']\n",
    "        return dgl.add_self_loop(graph)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, g, in_feats, n_hidden, n_layers, activation, dropout, gnn_encoder, k=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.g = g\n",
    "        self.gnn_encoder = gnn_encoder\n",
    "        if gnn_encoder == 'gcn':\n",
    "            self.conv = GCN(g, in_feats, n_hidden, n_hidden, n_layers, activation, dropout)\n",
    "        elif gnn_encoder == 'sgc':\n",
    "            self.conv = SGConv(in_feats, n_hidden, k=10, cached=True)\n",
    "\n",
    "    def forward(self, features):\n",
    "        if self.gnn_encoder == 'gcn':\n",
    "            features = self.conv(features)\n",
    "        elif self.gnn_encoder == 'sgc':\n",
    "            features = self.conv(self.g, features)\n",
    "        return features\n",
    "class GraphLocalGraphPooling(nn.Module):\n",
    "    def __init__(self, g, n_hop):\n",
    "        # TODO: Simulate random walk (randomly drop some subgraph)\n",
    "        super(GraphLocalGraphPooling, self).__init__()\n",
    "        A = g.adjacency_matrix().to_dense() \n",
    "        A = A + torch.eye(A.shape[0])\n",
    "        A_n = A\n",
    "        for i in range(n_hop):\n",
    "            A_n =  torch.matmul(A_n, A)\n",
    "        # TODO: Check matrix situation (sym, factor\n",
    "        A = torch.sign(A_n)\n",
    "        self.A = torch.matmul(torch.diag(1/torch.sum(A, dim=1)), A)\n",
    "        self.A = self.A.cuda()\n",
    "    def forward(self, feature):\n",
    "        # feature: [n_nodes, n_features]\n",
    "        feature = torch.matmul(self.A, feature)\n",
    "        return feature\n",
    "\n",
    "\n",
    "class GGD_Anomaly(nn.Module):\n",
    "    def __init__(self, g, in_feats, n_hidden, n_layers, activation, dropout, proj_layers, gnn_encoder, num_hop, subgraph_size, sampler=None):\n",
    "        super(GGD_Anomaly, self).__init__()\n",
    "        self.g = g\n",
    "        self.sampler = sampler\n",
    "        self.encoder = Encoder(g, in_feats, n_hidden, n_layers, activation, dropout, gnn_encoder, num_hop)\n",
    "        self.discriminator = Discriminator(n_hidden)\n",
    "        # self.discriminator = DiscriminatorCos()\n",
    "        self.graph_average_pooling = lambda x: x\n",
    "        if subgraph_size > 0:\n",
    "            self.graph_average_pooling = GraphLocalGraphPooling(g, subgraph_size)\n",
    "                \n",
    "        self.graph_conv_layers = self.encoder.conv.layers\n",
    "        self.mlp = torch.nn.ModuleList()\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        for i in range(proj_layers):\n",
    "            self.mlp.append(nn.Linear(n_hidden, n_hidden))\n",
    "        # GGD\n",
    "        self.lin = nn.Linear(n_hidden, n_hidden)\n",
    "    def forward(self, features):\n",
    "        \n",
    "        if self.sampler is not None:\n",
    "            # sample from graph\n",
    "            self.encoder.conv.g = self.sampler.sample()\n",
    "        features = self.dropout(features)\n",
    "        embedding_node = features\n",
    "        for i, graph_conv_layer in enumerate(self.graph_conv_layers):\n",
    "             embedding_node = graph_conv_layer._activation(torch.matmul(embedding_node, graph_conv_layer.weight) + graph_conv_layer.bias)\n",
    "\n",
    "\n",
    "        embedding_graph_pos = self.encoder(features)\n",
    "        # avg pooling \n",
    "        embedding_graph_readout = self.graph_average_pooling(embedding_node)\n",
    "        # Add skip connection\n",
    "        embedding_graph_proj = (embedding_graph_pos + embedding_graph_readout) / 2\n",
    "        # Positive branch of Anomaly\n",
    "        predicted_score_pos = self.discriminator(embedding_node, embedding_graph_proj)\n",
    "        # change shape from [n_nodes, 1] to [1, n_nodes]\n",
    "        predicted_score_pos = torch.swapaxes(predicted_score_pos, 0, 1)\n",
    "        \n",
    "        # Negative branch of Anomaly\n",
    "        perm = torch.randperm(self.g.number_of_nodes())\n",
    "        embedding_node_neg = embedding_node[perm]\n",
    "        predicted_score_neg = self.discriminator(embedding_node_neg, embedding_graph_proj)\n",
    "        predicted_score_neg = torch.swapaxes(predicted_score_neg, 0, 1)\n",
    "        \n",
    "        # ggd \n",
    "        ggd_score_pos = self.lin(embedding_graph_proj).sum(1).unsqueeze(0)\n",
    "        \n",
    "        embedding_graph_neg = self.encoder(features[perm])\n",
    "        ggd_score_neg = self.lin(embedding_graph_neg).sum(1).unsqueeze(0)\n",
    "        \n",
    "        if self.sampler is not None:\n",
    "            self.encoder.conv.g = self.g\n",
    "        return predicted_score_pos, predicted_score_neg, ggd_score_pos, ggd_score_neg, perm\n",
    "g = g.to(device)\n",
    "# Create GGD model\n",
    "\n",
    "# gamma = 0.07\n",
    "# for gamma in [0, 0.05, 0.07, 0.1, 0.2, 0.3, 0.4]:\n",
    "for gamma in [0.07]:\n",
    "    print(\"gamma =\", gamma)\n",
    "    for i in range(1):\n",
    "        ggd = GGD_Anomaly(\n",
    "            g,\n",
    "            ft_size,\n",
    "            args.n_hidden,\n",
    "            args.n_layers,\n",
    "            nn.PReLU(args.n_hidden),\n",
    "            args.dropout,\n",
    "            args.proj_layers,\n",
    "            args.gnn_encoder,\n",
    "            args.num_hop,\n",
    "            args.subgraph_size, \n",
    "            # sampler=GraphSampler(g, n_nodes=4)\n",
    "        )\n",
    "        if args.cuda:\n",
    "            ggd.cuda()\n",
    "        \n",
    "        #%%\n",
    "        \n",
    "        \n",
    "        ggd_optimizer = torch.optim.Adam(ggd.parameters(),\n",
    "                                         lr=args.ggd_lr,\n",
    "                                         weight_decay=args.weight_decay)\n",
    "        b_xent = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        #%% md\n",
    "        \n",
    "        # train GGD\n",
    "        \n",
    "        #%%\n",
    "        \n",
    "        cnt_wait = 0\n",
    "        best = 1e9\n",
    "        best_t = 0\n",
    "        counts = 0\n",
    "        avg_time = 0\n",
    "        dur = []\n",
    "        loss_list = []\n",
    "        \n",
    "        tag = str(datetime.datetime.now().strftime(\"%m-%d %H%M%S\"))\n",
    "        # print(\"Memory beg:\", torch.cuda.memory_allocated(device) / 1024 / 1024)\n",
    "        \n",
    "        epoch_list = []\n",
    "        auc_score_list = []\n",
    "        auc_pos_list = []\n",
    "        auc_neg_list = []\n",
    "        pos_std = []\n",
    "        neg_std = []\n",
    "        score_std = []\n",
    "        label_positive = torch.zeros(1, g.number_of_nodes()).cuda()\n",
    "        label_negative = torch.ones(1, g.number_of_nodes()).cuda()\n",
    "        with tqdm(total=args.n_ggd_epochs) as pbar:\n",
    "            pbar.set_description('Training')\n",
    "            for epoch in range(args.n_ggd_epochs):\n",
    "                if epoch % args.eval_freq == 0:\n",
    "                    ggd.eval()\n",
    "                    with torch.no_grad():\n",
    "                        pos_prob_list = []\n",
    "                        neg_prob_list = []\n",
    "                        # for i in range(args.auc_test_rounds):\n",
    "                        #     s_positive, s_negative, ggd_score_pos, ggd_score_neg, perm = ggd(features)\n",
    "                        #     inverse_perm = torch.argsort(perm)\n",
    "                        #     pos_prob_list.append(s_positive.detach()[0])\n",
    "                        #     neg_prob_list.append(s_negative.detach()[0][inverse_perm])\n",
    "                        \n",
    "                        # Prev Expr: dropout not used in eval (auc=87.4%)\n",
    "                        pos_prob_list.append(ggd(features)[0].detach()[0])\n",
    "                        pos_prob = torch.mean(torch.stack(pos_prob_list), axis=0)\n",
    "                        #neg_prob = torch.mean(torch.stack(neg_prob_list), axis=0)\n",
    "                        #ano_score = (neg_prob - pos_prob).cpu().numpy()\n",
    "                        epoch_list.append(epoch)\n",
    "                        auc_pos_list.append(roc_auc_score(ano_label, pos_prob.cpu().numpy()))\n",
    "                        # auc_neg_list.append(roc_auc_score(ano_label, neg_prob.cpu().numpy()))\n",
    "                        # auc_score_list.append(roc_auc_score(ano_label, ano_score))\n",
    "                        # pos_std.append(np.std(pos_prob.cpu().numpy()))\n",
    "                        # neg_std.append(np.std(neg_prob.cpu().numpy()))\n",
    "                        # score_std.append(np.std(ano_score))\n",
    "                \n",
    "                t0 = time.time()\n",
    "                ggd.train()\n",
    "                if epoch >= 3:\n",
    "                    t0 = time.time()\n",
    "                    \n",
    "                ggd_optimizer.zero_grad()\n",
    "                s_positive, s_negative, ggd_score_pos, ggd_score_neg, perm = ggd(features)\n",
    "                # perm not used\n",
    "                loss_anomaly = b_xent(s_positive, label_positive) + b_xent(s_negative, label_negative)\n",
    "                loss_ggd = b_xent(ggd_score_pos, label_positive) + b_xent(ggd_score_neg, label_negative)\n",
    "                loss = (1-gamma) * loss_anomaly + gamma * loss_ggd\n",
    "                \n",
    "                loss.backward()\n",
    "                ggd_optimizer.step()\n",
    "            \n",
    "                comp_time = time.time() - t0\n",
    "                if loss < best:\n",
    "                    best = loss\n",
    "                    best_t = epoch\n",
    "                    cnt_wait = 0\n",
    "                    # torch.save(ggd.state_dict(), 'checkpoints_ggd/best_ggd' + tag + '.pkl')\n",
    "                else:\n",
    "                    cnt_wait += 1\n",
    "            \n",
    "                if cnt_wait == args.patience:\n",
    "                    print('Early stopping!')\n",
    "                    break\n",
    "            \n",
    "                if epoch >= 3:\n",
    "                    dur.append(time.time() - t0)\n",
    "                \n",
    "                pbar.set_postfix(loss=loss.item())\n",
    "                pbar.update(1)\n",
    "                loss_list.append((loss.detach().cpu().item(), loss_anomaly.detach().cpu().item(), loss_ggd.detach().cpu().item()))\n",
    "                avg_time += comp_time\n",
    "                counts += 1\n",
    "        \n",
    "        print(i, max(auc_pos_list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXgUVfbw8e/JwpJAgLCJBASEAYIkAQIEcYyKKAiyCSOIo4w6yMww4ob6/hwEdVRwGRVFEBXBXQdHQdkEAdmXAEHZCSAQ1rAkASRrn/ePbmJIGgghlYU+n+fph6q6t6rP7Sf06VvLvaKqGGOM8V1+JR2AMcaYkmWJwBhjfJwlAmOM8XGWCIwxxsdZIjDGGB8XUNIBXKwaNWpogwYNSjoMY4wpU9asWXNEVWt6KytziaBBgwbExcWVdBjGGFOmiMjuc5XZqSFjjPFxlgiMMcbHWSIwxhgfV+auERhjSr/MzEwSExNJS0sr6VB8ToUKFQgLCyMwMLDA+1giMMYUucTERCpXrkyDBg0QkZIOx2eoKkePHiUxMZGGDRsWeD87NWSMKXJpaWlUr17dkkAxExGqV69+0T0xSwTGGEdYEigZhfncLREYY4yPs0RgjDHFaPr06YwePRqAb7/9lk2bNuWUPfPMM8ybN6/YY7KLxcYYU4x69OhBjx49AHci6N69O+Hh4QA899xzJRKT9QiMI2YnzKbp201pPLYxo5eMzleekpbC7Z/fTuSESFq804IP132YU5aclkzfr/rS7O1mNB/XnOV7lwMQfzCemPdjiJoQRfTEaFbtWwXAqn2riJoQRdSEKCInRPLN5m+Kp5GmVOvVqxdt2rShRYsWTJw4MWd7pUqVcpanTp3KoEGDADh06BC9e/cmMjKSyMhIli1blu+YlSpV4rHHHqN169Z06tSJpKQkAOLj44mJiSEiIoLevXtz/PhxAMaOHUt4eDgRERH0798fgMmTJzN06FCWLVvG9OnTGT58OFFRUezYsYNBgwYxdepUZs2axZ/+9Kec9124cCG33347AD/88AMdOnSgdevW9OvXj5MnT17yZ2U9AlPksl3Z/GPmP5j757mEhYTR9r229Gjag/Ca4Tl1xq0eR3iNcL4b8B1Jp5Jo+nZTBkYMpJx/OYbNHkaXxl2Y+qepZGRn8FvmbwA8MfcJRsaOpGuTrszcPpMn5j7BwkELuabWNcQNjiPAL4ADJw4QOSGS25veToCf/XmXBg/Pfpj4g/FFesyoK6J4o8sb560zadIkQkNDOX36NG3btuWOO+6gevXq56z/0EMPERsbyzfffEN2drbXL9hTp07RunVrXnvtNZ577jmeffZZ3n77be655x7eeustYmNjeeaZZ3j22Wd54403GD16NLt27aJ8+fIkJyefdaxrr72WHj160L17d/r27XtWWefOnXnwwQc5deoUwcHBfPnll9x5550cOXKEf//738ybN4/g4GDGjBnDf/7zH5555pmL+PTysx6BKXKr9q2icWhjGlVrRDn/cvRv0Z9pW6adVUcQTmScQFU5mXGS0IqhBPgFkJqeyqLdi7i/1f0AlPMvR9UKVd37iJCangq4exRXVr4SgKDAoJwv/bSsNLtbxQDuX+ORkZHExMSwd+9etm/fft768+fP529/+xsA/v7+VKlSJV8dPz8/7rzzTgDuvvtulixZQkpKCsnJycTGxgJw7733smjRIgAiIiIYOHAgn3zyCQEBBf9hEhAQQJcuXfjuu+/IyspixowZ9OzZkxUrVrBp0yY6duxIVFQUU6ZMYffuc44lV/D3u+QjGJPHvhP7qBdSL2c9LCSMlftWnlVnaLuh9PiiB1f+50pOpJ/gy75f4id+7Dy+k5pBNfnLtL+w/tB62tRpw5td3iS4XDBv3PoGt35yK4/PfRyXulh23+9d95WJK7lv+n3sTt7Nx70/tt5AKXKhX+5OWLhwIfPmzWP58uUEBQVxww035Nxbn/uHwqU++XyhHx0zZsxg0aJFTJ8+neeff56NGzcW+Nh33nkn48aNIzQ0lLZt21K5cmVUlc6dO/P5559fUtx5WY/AFDlVzbdNOPs/zJwdc4iqHcX+R/cTPySeobOGkpqeSpYri7UH1vK36L+x7sF1BAcG51xjGB83ntdvfZ29j+zl9Vtf5/7p9+ccr31Yezb+fSOr/7qal5a8RFqWDW3gy1JSUqhWrRpBQUFs2bKFFStW5JTVrl2bzZs343K5+Oab368nderUifHjxwOQnZ1NampqvuO6XC6mTp0KwGeffcZ1111HlSpVqFatGosXLwbg448/JjY2FpfLxd69e7nxxht5+eWXSU5Ozne6qXLlypw4ccJrG2644QbWrl3Le++9l9MLiYmJYenSpSQkJADw22+/sW3btsJ+TDksEZgiFxYSxt7UvTnriamJOadxzvgw/kP6NO+DiNA4tDENqzZky5EthIWEERYSRvuw9gD0De/L2oNrAZiyfgp9mvcBoF94v5yLxbk1r9mc4HLBbDi8wanmmTKgS5cuZGVlERERwYgRI4iJickpGz16NN27d+emm26iTp06OdvffPNNFixYQMuWLWnTpo3XX+/BwcFs3LiRNm3aMH/+/Jxz81OmTGH48OFEREQQHx/PM888Q3Z2NnfffTctW7akVatWPPLII1StWvWs4/Xv359XXnmFVq1asWPHjrPK/P396d69O7NmzaJ79+4A1KxZk8mTJzNgwAAiIiKIiYlhy5Ytl/6BqWqZerVp00ZN6ZaZnakN32ioO4/t1PSsdI0YH6EbDm04q86Q74boyAUjVVX14ImDeuVrV2rSqSRVVb1u0nW6JWmLqqqOXDBSH5/zuKqqNnu7mS7YtUBVVeftmKet322tqqo7j+3UzOxMVVX99fivWufVOjnHMiVj06ZNJR2CI4KDg0s6hALx9vkDcXqO71VHT6SKSBfgTcAfeF9VR+cprwZMAq4G0oD7VNV+ypVxAX4BvH3b29z6ya1kazb3Rd1Hi1otmBA3AYAh0UMYETuCQd8OouX4lqgqY24eQ42gGgC81fUtBv5vIBnZGTSq1ogPe7pvLX3v9vcYNnsYWa4sKgRUYGJ39y2BS/YsYfTS0QT6BeInfrzT7Z2cYxljLkzUy/ncIjmwiD+wDegMJAKrgQGquilXnVeAk6r6rIg0A8apaqfzHTc6OlptqkpjSrfNmzfTvHnzkg7DZ3n7/EVkjapGe6vv5DWCdkCCqu5U1QzgC6BnnjrhwI8AqroFaCAitR2MyRhTTJz6kWnOrzCfu5OJoC6wN9d6omdbbuuBPgAi0g64CgjLeyARGSwicSISd+ZJPmNM6VWhQgWOHj1qyaCYqWc+ggoVKlzUfk5eI/B2g23ev4rRwJsiEg/8AqwDsvLtpDoRmAjuU0NFHKcxpoiFhYWRmJiI/XArfmdmKLsYTiaCRKBervUwYH/uCqqaCvwFQNxPZuzyvIwxZVhgYOBFzZBlSpaTp4ZWA01EpKGIlAP6A9NzVxCRqp4ygAeARZ7kYIwxppg4lghUNQsYCswBNgNfqepGERkiIkM81ZoDG0VkC9AVGOZUPKbsOXDiALGTYzl48mBJh2LMZc3R5whUdSYwM8+2CbmWlwNNnIzBlF3PL3qeJXuW8PxPzzOu27iSDseYy5aNzGVKjWxXNjuP72TdwXUs/HUh7655F5e6eHfNu5QPKM81ta4htGIoyWnJJKclk5KWQkp6ClmuLOqF1OPaetfSoV4H/MRGTjHmYlgiMMVOVdmTsocNhzew4fAGNiZtZMPhDWw+sjlnsDg//FDPTWbZms3rK173eqxK5SrhJ345w1PXCKrBlZWvZG/KXk5lnuLqalfTp3kf+jTvQ6srWiEipGWlMTthNj/9+hPX1ruWvuF9L8uhq1cmrmRF4gpubXwrzWo0y1d+5tbOwrZdVTmddZqgwCCv5VuObCFufxx9w/tSIeDibmc0xcuxJ4udYk8Wlx1ZriwW717MxqSNbEraxPZj2zl86jA7j+/kZMbvozCGhYTRomYLrql1DdfUuoY6lerQ68teZ40gWjGgIgvvXUigfyBVK1SlaoWqhJQPwd/PH4Bjp48xJ2EOc3fO5fCpwzSo2oCgwCDWHFjDT7/+RLZmU6dSHepUrsO2o9s4mXESQVCUjvU6MrnXZBqHNgZgw+ENTI6fTHBgMD2b9cxJIGeoKqcyT1Gp3O8zXRWlzOxMAv0Dz1v+7pp32Zuyl7Z13ZP+lPMvl1OemJrIqIWj+GDdB4D7s5v757l0rN+RtKw0Jq6ZyMQ1E9lyZAtXh17NmJvH0KtZr4uKUVUZ8PUApm+dzqyBs4htEJtTdjLjJK8sfYWXl71MWlYanRt15vu7vj8rxgs5nXmaioEVLyqmgtp/Yj8/7vyR0IqhxITFUD3o3JPVXE7O92SxJQJT5DKzM/n45495cfGL7DjuHlGxSvkqNK3RlCsqXUH9kPq0rN2SFjVb0KJWi5yJZ874+4y/88G6D8jIzsjZVs6/HA+0eqBQ1wqO/HaE77Z+x/xf53Ps9DHqVq5Lv/B+XH/V9Xzy8ycMnzuckxkn6dWsFxnZGUzbOo1Av0CyNRuXumhYtSG9m/WmelB1Eo4lMDthNgdOHqB1ndbc1OAmHox+MCeJ7E3Zy5PznmTm9pnUCKpBh3od6Nu8L81rNqdxaGOW7FnCuNXj2HB4A/dG3svj1z6On/iR5cpiSvwUxiwdw/Zj24msHUm/8H7c1fIuGlRtwKFTh0g4lsCqfat4e9Xb7EreRaBfIJmuTFrWasmcu+fgJ368tOQlJsRNwKUuHmr/EPe3up8eX/QgNT2Vaf2nMWLBCObtnEfrOq25pdEtzNg+g18O/8Kw9sN4/dbXC9w7eH/t+/z1u78CEFE7gnUPrsvpmf3xwz/y86GfuaP5HURdEcWIBSOoHVybqCuieLf7u1xV9SoOnjzIq8tepX6V+vyz3T/Pet/Hf3ic15a/Ru9mvfn8js8pH1D+rPfeeHgj249tp2vjrvnKTmeepscXPVh7YC13NL+DkbEjqRvy+3OsJ9JPEDkhkl3J7rvUr6pyFRv+vsGxpF6aWCIwxSI9K53J8ZN5aclL7E7ZTZs6bXiy45N0rN+ROpXqFPhLptW7rbxObRh1RRTrHlxX1GGzO3k3b6x4g09/+RR/P3/+2vqvDGs/DEWZtmUaX2/+mnk755HpyqRahWp0vrozzWs0Z3bCbNYeWEu2ZtO1cVcUZcGuBSjKgGsGcCLjBAt2LeDo6aOAO5llZGdQrUI1mtVoxvLE5fRu1puujbvy8rKXSTiWQNsr29KlcRe+3/Y98QfjUTTnC/+Ma+tdy+MdHqdH0x5M2zqNe765h/IB5UnLSiM9K517I+9lROwIGlRtALhP0XT6qBP7T7gf43n/9ve5v7V7LofM7EyGzx3Omyvf5KF2D/HqLa9y8ORBsjWbbUe38dKSlziRfoIZd82gdiX36C+nMk5R/436XFPrGga3Hszd39zN67e+zsMxDzPk+yG8t/Y9vh/wPV2bdAVgSvwU5u2ax3dbv6NGUA0ebPMgLy55keQ099SNZ/bNyM7g7VVv89gPjxFZO5L1h9bTL7wfn9/xeU7Pb0LcBP4x8x+41EW9kHq83+N9brn6FsDdS7nrf3fx5YYv6VCvA3H742heo3nONKYA9027jynrp/BZn89Iy0pj0LRBDL92OC93fjnn8006lcRbq94ivGY4/a/pX+R/byXlfImgxIeVvtiXDUNd+rhcLn037l0N+0+YMgpt/157nbltprpcrpIOrcikZaZpelZ6vu37U/frk3Of1EZvNtJGbzbSgV8P1F3Hd+WUp2el60+//qQfrP1AH571sE5aO0lPZZxSl8ulry17Tf2e9VNGoRHjI3TalmlnfWY7ju3QN1e8qcN/GK6vL39dv9/6va7YuyJfDIt3L9ZbPr5FB08frFuPbPUa/4ETB/SFRS/ool8X5StzuVw6bNYwZRQa+FygMoqcV9ALQcooNHJ8pB4/fVxVVSfGTVRGoUt2L1GXy6W3f3a7ln++vL618i1lFPrI7Ee8xrBw18Kc48d+GKtbkrZot0+7acV/V9RZ22dpi3EtlFFopymdNCMrQ19b9poyCn1h0Quqqvrd1u/U71k/7fZpN526caqGjwtXRqGDvh2kD818SNu820YZhY5ePFpVVb/a8JUyCn1r5VuamZ2pD373oDIKffrHp3NiemDaA+r/rL++uvRVPZF+QhNTEvUPb/0hp/3vxr3rtS3e7Evdp8v2LCvQ331J/N/gPMNQW4/AXJLktGQGfTuIaVun0bFeR0bGjuTmRjdflhdfnZCYmsihk4doVadVid/tNG3LNObsmMM1ta6hYkBFQiuGcsvVt7B4z2K6fdaNQZGDGN99PK3ebUWAXwBrB69FRDh08hAREyI4fOowf6j+B+L+Gkfl8pW9vseWI1vYl7qPGxveiJ/4kZiaSOSESI6dPkZoxVBevvllBkYMzLm43OfLPszdOZfx3cbz4PcPEl4znIX3LiS4XDCnM0/zfz/+H2+teosKARVoUasF/cL78ViHxxARVJVbPrmFFYkriKwdydK9S3m8w+O8dPNLOT2Eo78dpfPHnVl3cB21gmtxOvM0ivLdgO8Ys3QMc3fMZWTsSIbFDCOkfMhZbTl++jivLHuFpFNJrNi3ImcypFZXtKJd3XZEXxlNg6oN6NSw01n/H5buWUqXT7sQXjOcxzo8Ro+mPYrlYrr1CIwjjv52VFu/21oDngvQ15e/fln1AMzZHpr5kPo/66+9vuiljEK/3PDlWeWbDm/Sf/34L92fuv+ij/3LoV/02YXP6o5jO/KVbT2yNacX0ejNRnrgxIF8dU5nntas7Cyvx956ZKuGjglVGSX6+vLXvdZxuVz65YYvtfHYxtp/av+cXlVqWqp2/6y7MgptNaGVrj+4XlVVU9JSdPzq8drynZbKKDT4hWC9acpN+uzCZ/WfM/+pVUdXzelJMQqdsHpCznvN3zlfA54LyNmPUegfJ/3xnPEXJaxHYIpawrEE7vjqDrYe2co3d36Tcz7YXJ4OnzpMs7ebcTztOANbDuSTPp8U23vHH4wn/mA8vZv1pkqFKhe9f3JaMqnpqdSvUr9Q7//1pq8Z/P1g0rPSeaXzK7yw+AX2ndhHWEgYE7pNoNsfuuXbJyUthcV7FvPcT8+xO2U3vw77lUD/QFq804IsVxY/3vMjFQMqMnblWF5c8iJhIWGM7TKW25vezorEFbyz+h3qVKpDTFgMi3Yv4sHoB7mm1jWFiv8Mu1hsitSnP3/KkBlDCPAL4Mu+X+ZcrDOXt32p+9iUtIkbG96Yc2rFVxw4cYDeX/Zm5b6V+IkfC+5dwPVXXX/B/RbtXkTs5FgeaPUADao24F8L/sW0/tPo0bQH4D4j899N/+XlpS+z5sAaggKD+C3zt3zHCQsJY+ZdM2lZu2Wh22CJoBRZmbiSLUe2UD6gPP7iT6s6rTiRfoJawbX47JfPqFelHrWDa3P9Vdfn3ClRWpzMOMnQmUOZsn4K19W/jk/7fFroX1nGlDXpWem8tvw1rr/qeq6rf12B9xv+w3BeXf4qADc0uIH598zPdw3tdOZpXlz8IsdOH+OGBjfQqVEnUtJS2Hl8JwF+AXT+uDOZrkye6vgUL938UqHit0RwAU/MfQJBGNN5TJEeN7fU9FRGLxnNmKVjcKnrgvXbXtmWYe2H0fnqztQKruVYXAX186GfuXPqnWw9spUR149gROwIn/tVaExhLdq9iD0pewr9lPW2o9uYvnU60VdGc0ODGwoVgyWC80g6lUStV91ftDrSmc8iIzuDmz+6mcV7FtOzaU8e7fAogX6BHE87zuakzYD7HOx9re7jVOYpfjn0C0/9+BQHTx6kSvkqPP3Hp7m/9f0kHEtg4+GNXB16NR3rdSyWHoOq8t7a93ho1kOEVgzl0z6fcmPDGx1/X2NM0SqxRCAiXYA3AX/gfVUdnae8CvAJUB/3uEevquqH5ztmUSWCT3/+lIqBFSnnX47bP78dgLSn0/I9qXipDp08RJdPuxB/MJ6Pen3EnyP/XKD90rPSiT8Yz9Pzn+bHXT/mDIdwRv0q9Rlz8xjubHGnY7dqutTFI7MfYeyqsdx69a181PujUtE7McZcvBKZvF5E/IFxuOcZCAcGiEh4nmr/ADapaiRwA/BarolqHJOelc7d39zNHV/dwa7jv0+Iduax86KyfO9yenzRg01Jm/iq71cFTgIA5QPK0z6sPfPumUf8g/E82uFRxnYZy/Z/buervl9RvWJ1Bnw9gNjJsSzevZjjp48XaeyZ2Znc/b+7GbtqLI/EPMLMgTMtCRhzmXLyJG87IEFVdwKIyBdAT2BTrjoKVPZMU1kJOIaXOYuL2uI9i3OWZyb8Pl3CruO7vI7SeLFS0lKYuX0mf/7mz2RrNi/e9CL9WvQr9PEir4gk8orInPXGoY3p07wPk9ZN4v/m/x/XT3bfvVAjqAa3NbmNf7b7J9FXen9upCB+y/yNP/33T8zYPoOXOr3EU9c9VehjGWNKPycTQV1gb671RKB9njpv456+cj9QGbhTNf+VVBEZDAwGqF//0u9Syd0LmJ0wO2cMmKTfLn2i7WxXNu3fb8/Wo1sJ8AtgzsA5jtxe6e/nz1/b/JV+Lfoxd8dc9qTs4ZfDv/D15q/5aP1H3HL1LYyMHcm19a4t8DFVla83f82/5v+LbUe3Mb7beIZED7nwjsaYMs3JZ9q9nbjOe0HiViAeuBKIAt4WkZB8O6lOVNVoVY2uWbPmJQe2N3XvWetnviyP/Hbkko89Y/sMth7dyqCoQWz42wbH77GvWqEq/Vr047FrH2Nyr8nse3QfY24ew7oD6+g4qSPXfnAt41aNY+2BtaRnpZ/zOL8m/0rXT7vS77/98PfzZ8ZdMywJGOMjnOwRJAL1cq2H4f7ln9tfgNGex58TRGQX0AxY5WBcJKYmcmXlKzmdeZrjace5vv71LN2zlKRTl9YjmJMwhz5f9qFJaBMmdJtQ5BeeCyKkfAhPdHyCf7T9BxPXTOSDdR8wdNZQAAL8AmhRswWt6rSiRsUapKankpqRSnJaMvN3zaecfznGdhnL39v+vdQ9w2CMcY6TiWA10EREGgL7gP7AXXnq7AE6AYtFpDbQFNjpYEyAu0cQFhKGIKzct5KoK6KoEVTjknsEzy96nioVqjD77tklkgRyCy4XzCMdHuHhmIfZcXwH6w6sY91B92vW9lmkpKdQpXwVQsqHEFI+hHsj7+WZ2GcICwkr0biNMcXPsUSgqlkiMhSYg/v20UmqulFEhnjKJwDPA5NF5Bfcp5KeVNVLPz9zAQdOHKBJ9SZM6jGJ/276L93/0J2RC0de0jWCGdtmsHTvUl7p/AqNqjUqwmgvjYjQOLQxjUMbX9IFa2PM5cvRR0NVdSYwM8+2CbmW9wPFPlDN4VOH6VivI9UqVmNwm8GA+46bwiaCHcd2cMdXd1CtQjUGRQ0qwkiNMcZ5JTsAegnIdmVz9PTRfPfE1w2py77UfWS5sgo0BERuo5eMxk/8WH7/cmoE1SjKcI0xxnE+lwiOnT6GS135EkH9kPrsTtlN0AtBdP204EMq70nZwye/fMLAlgNpWqNpUYdrjDGO87lEcPjUYQBqBp99G+pVVa8CINOVyQ87fijw8R774TEEYUTsiKIL0hhjipHPJYIz1wHy9QjyDKdckCEbjvx2hKmbpvJIzCM2HLMxpszyuUSQ0yMIOrtH0PbKtsSExdAhrAMAO49f+C7W4XOHA3Bbk9uKOEpjjCk+PpsIaleqfdb26kHVWX7/ct7p9g5w4QHoDpw4wOT4yQCXNK6PMcaUNJ9MBIJQvWJ1r+X1QtwPQ+9L3Xfe48zdOReARYMWlfjDY8YYcyl8MhHUCKpxziEUQiuGUt6/PImpiec9ztydc6kZVJOO9Ts6EaYxxhQbn0wE5xtXX0QICwlj7s65jF89nlMZp/LVOZlxktkJs7m50c34ic99hMaYy4zPfYtdKBGA++Gy9YfW8/eZf+ezXz7LV/7onEc5dvoY97W6z6kwjTGm2Fgi8OLqalfnLK8/tP6ssmOnj/Fh/IcMaTOEmxvd7EiMxhhTnCwRePHcjc/RIawDQYFB/Hzo57PK5iTMIcuVxT2R9zgZpjHGFBtHE4GIdBGRrSKSICL55jsUkeEiEu95bRCRbBEJdSqe9Kx0UtJTLpgIwkLCWHb/Mu6JuIdfDv+Ce7oE93AS/178b+pWrkvbum2dCtMYY4pViU5er6qvqGqUqkYB/w/4SVWPORXTuZ4qPpeWtVuSnJZMzAcxzN0xl5um3MS2o9sY23WsXSQ2xlw2Snry+twGAJ87GE/Ow2QFTQQRtSMAWLVvFbd84h4t+6dBP3H9Vdc7E6AxxpQAJ3/Wepu8vq63iiISBHQBvnYwnotOBG3qtOG2JrfRrm47AO6Lus+SgDHmsuNkj6Agk9efcTuw9FynhURkMDAYoH79wg/uduy0+/Dneqo4r4qBFZlx1wwAViauJPKKyEK/tzHGlFZO9ggKMnn9Gf05z2khVZ2oqtGqGl2zZs1zVbug5LRkAKpUqHLR+7YPa0+FgAqFfm9jjCmtnEwEOZPXi0g53F/20/NWEpEqQCwwzcFYAEhJSwGgaoWqTr+VMcaUGSU9eT1Ab+AHVc0/lkMRS0lPoZx/Oftlb4wxuZTo5PWe9cnAZCfjOCM5LZkq5S/+tJAxxlzOfOpm+JT0FDstZIwxefhUIkhOSy7UhWJjjLmc+VQiSElLsVNDxhiTh08lghMZJwgpH1LSYRhjTKniU4kgMzuTQP/Akg7DGGNKFZ9KBFmuLAL8HL1RyhhjyhyfSgTZmm2JwBhj8vCpRJDlyiJALBEYY0xuvpcIrEdgjDFn8blE4O/nX9JhGGNMqeJzicB6BMYYczafSgTZLrtYbIwxeflUIrAegTHG5OdoIhCRLiKyVUQSROSpc9S5QUTiRWSjiPzkZDyWCIwxJj/HvhVFxB8YB3TGPVvZahGZrqqbctWpCrwDdFHVPSJSsMmECynLlYW/2MViY4zJzckeQTsgQVV3qmoG8AXQM0+du4D/qeoeAFU97FQwLnWhqPUIjDEmD0n2KB4AAA4GSURBVCcTQV1gb671RM+23P4AVBORhSKyRkTu8XYgERksInEiEpeUlFSoYLJd2QCWCIwxJg8nE4F42aZ51gOANkA34FZghIj8Id9ORTB5fZYry/2GlgiMMeYsTn4rJgL1cq2HAfu91Dnima/4lIgsAiKBbUUdjCUCY4zxzskewWqgiYg0FJFyQH9gep4604A/ikiAiAQB7YHNTgRjicAYY7xz7FtRVbNEZCgwB/AHJqnqRhEZ4imfoKqbRWQ28DPgAt5X1Q1OxHMmEdgQE8YYczZHfx6r6kxgZp5tE/KsvwK84mQc4B6CGqxHYIwxefnMk8V2asgYY7yzRGCMMT7OEoExxvg4n0sENsSEMcaczWcSgT1ZbIwx3vlMIrBTQ8YY450lAmOM8XGWCIwxxsf5XCKwJ4uNMeZsPpcIrEdgjDFnK1AiEJEYEamca72yiLR3LqyiZ0NMGGOMdwXtEYwHTuZaP+XZVmZYj8AYY7wraCIQVc2ZVEZVXTg8YF1Rs0RgjDHeFTQR7BSRh0Qk0PMaBuy80E4i0kVEtopIgog85aX8BhFJEZF4z+uZi21AQdmTxcYY411BE8EQ4FpgH+5ZxdoDg8+3g4j4A+OArkA4MEBEwr1UXayqUZ7XcwWO/CJZj8AYY7wr0Leiqh7GPcPYxWgHJKjqTgAR+QLoCWy6yOMUCRtiwhhjvCvQt6KIfEj+iedR1fvOs1tdYG+u9TM9ibw6iMh63PMZP66qG728/2A8PZD69esXJOR82tZty5ReU6gbUrdQ+xtjzOWqoD+Pv8+1XAHoTf6J6PMSL9vyJpO1wFWqelJEbgO+BZrk20l1IjARIDo6Ol9CKogGVRvQoGqDwuxqjDGXtYKeGvo697qIfA7Mu8BuiUC9XOth5Ekeqpqaa3mmiLwjIjVU9UhB4jLGGHPpCvtkcRPgQudoVgNNRKShiJTDfY1heu4KInKFiIhnuZ0nnqOFjMkYY0whFPQawQl+P62jwCHgifPto6pZIjIUmAP4A5NUdaOIDPGUTwD6An8TkSzgNNA/9/MKxhhjnCcF/d4VkVDcPYEKnk2qqoucCuxcoqOjNS4urrjf1hhjyjQRWaOq0d7KCtojeAAYhvs8fzwQAywHbiqqII0xxpSMgl4jGAa0BXar6o1AKyDJsaiMMcYUm4ImgjRVTQMQkfKqugVo6lxYxhhjiktBnyNIFJGquO/znysix7nwcwTGGGPKgII+R9DbszhKRBYAVYDZjkVljDGm2Fz0wDuq+pMTgRhjjCkZPjNVpTHGGO8sERhjjI+zRGCMMT7OEoExxvg4SwTGGOPjLBEYY4yPs0RgjDE+ztFEICJdRGSriCSIyFPnqddWRLJFpK+T8RhjjMnPsUQgIv7AOKArEA4MEJHwc9Qbg3veAmOMMcXMyR5BOyBBVXeqagbwBdDTS71/Al8Dhx2MxRhjzDk4mQjqAntzrSd6tuUQkbpAb2DC+Q4kIoNFJE5E4pKSbPRrY4wpSk4mAvGyLe90aG8AT6pq9vkOpKoTVTVaVaNr1qxZZAEaY4wpxKBzFyERqJdrPYz8Q1dHA1945q+vAdwmIlmq+q2DcRljjMnFyUSwGmgiIg2BfUB/4K7cFVS14ZllEZkMfG9JwBhjipdjiUBVs0RkKO67gfyBSaq6UUSGeMrPe13AGGNM8XCyR4CqzgRm5tnmNQGo6iAnYzHGGOOdPVlsjDE+zhKBMcb4OEsExhjj4ywRGGOMj7NEYIwxPs4SgTHG+DhLBMYY4+MsERhjjI+zRGCMMT7OEoExxvg4SwTGGOPjLBEYY4yPK9HJ60Wkp4j8LCLxnhnIrnMyHmOMMfk5NvporsnrO+OepGa1iExX1U25qv0ITFdVFZEI4CugmVMxGWOMya9EJ69X1ZOqemb6ymDyT2VpjDHGYSU6eT2AiPQWkS3ADOA+B+MxxhjjRUlPXo+qfqOqzYBewPNeDyQy2HMNIS4pKamIwzTGGN/mZCIoyOT1OVR1EXC1iNTwUjZRVaNVNbpmzZpFH6kxxvgwJxNBzuT1IlIO9+T103NXEJHGIiKe5dZAOeCogzEZY4zJo6Qnr78DuEdEMoHTwJ25Lh4bY4wpBlLWvnejo6M1Li6upMMwxpgyRUTWqGq0tzJ7stgYY3ycJQJjjPFxlgiMMcbHWSIwxhgfZ4nAGGN8nCUCY4zxcZYIjDHGx1kiMMYYH2eJwBhjfJwlAmOM8XGWCIwxxsdZIjDGGB9nicAYY3yco4lARLqIyFYRSRCRp7yUDxSRnz2vZSIS6WQ8xhhj8nMsEYiIPzAO6AqEAwNEJDxPtV1ArKpG4J6mcqJT8RhjjPHOyR5BOyBBVXeqagbwBdAzdwVVXaaqxz2rK3BPZ2mMMaYYOZkI6gJ7c60nerady/3ALG8FNnm9McY4x8lEIF62eZ0OTURuxJ0InvRWbpPXG2OMcxybsxh3D6BervUwYH/eSiISAbwPdFVVm7jeGGOKmZM9gtVAExFpKCLlgP7A9NwVRKQ+8D/gz6q6zcFYjDHGnINjPQJVzRKRocAcwB+YpKobRWSIp3wC8AxQHXhHRACyzjW5sjHGGGeIqtfT9qVWdHS0xsXFlXQYxhhTpojImnP90LYni40xxsdZIjDGGB9nicAYY3ycJQJjjPFxlgiMMcbHWSIwxhgfZ4nAGGN8nCUCY4zxcZYIjDHGx1kiMMYYH2eJwBhjfJwlAmOM8XGWCIwxxsc5mghEpIuIbBWRBBF5ykt5MxFZLiLpIvK4k7EYY4zxzrH5CETEHxgHdMY9W9lqEZmuqptyVTsGPAT0cioOY4wx5+dkj6AdkKCqO1U1A/gC6Jm7gqoeVtXVQKaDcRhjjDkPJxNBXWBvrvVEz7aLJiKDRSROROKSkpKKJDhjjDFuTiYC8bKtUNOhqepEVY1W1eiaNWteYljGGGNyczIRJAL1cq2HAfsdfD9jjDGF4GQiWA00EZGGIlIO6A9Md/D9jDHGFIJjdw2papaIDAXmAP7AJFXdKCJDPOUTROQKIA4IAVwi8jAQrqqpTsVljDHmbI4lAgBVnQnMzLNtQq7lg7hPGRljjCkh9mSxMcb4OEsExhjj4ywRGGOMj7NEYIwxPs4SgTHG+DhLBMYY4+MsERhjjI+zRGCMMT7OEoExxvg4SwTGGOPjLBEYY4yPs0RgjDE+zhKBMcb4OEcTgYh0EZGtIpIgIk95KRcRGesp/1lEWjsZjzHGmPwcSwQi4g+MA7oC4cAAEQnPU60r0MTzGgyMdyoeY4wx3jnZI2gHJKjqTlXNAL4Aeuap0xP4SN1WAFVFpI6DMRljjMnDyYlp6gJ7c60nAu0LUKcucCB3JREZjLvHAHBSRLYWMqYawJFC7lvaWFtKJ2tL6XO5tAMurS1XnavAyUQgXrZpIeqgqhOBiZcckEicqkZf6nFKA2tL6WRtKX0ul3aAc21x8tRQIlAv13oYsL8QdYwxxjjIyUSwGmgiIg1FpBzQH5iep8504B7P3UMxQIqqHsh7IGOMMc5x7NSQqmaJyFBgDuAPTFLVjSIyxFM+AffE9rcBCcBvwF+cisfjkk8vlSLWltLJ2lL6XC7tAIfaIqr5TskbY4zxIfZksTHG+DhLBMYY4+N8JhFcaLiL0kZEJonIYRHZkGtbqIjMFZHtnn+r5Sr7f562bRWRW0sm6vxEpJ6ILBCRzSKyUUSGebaXxbZUEJFVIrLe05ZnPdvLXFvOEBF/EVknIt971stkW0TkVxH5RUTiRSTOs63MtUVEqorIVBHZ4vk/06FY2qGql/0L98XqHUAjoBywHggv6bguEPP1QGtgQ65tLwNPeZafAsZ4lsM9bSoPNPS01b+k2+CJrQ7Q2rNcGdjmibcstkWASp7lQGAlEFMW25KrTY8CnwHfl9W/MU98vwI18mwrc20BpgAPeJbLAVWLox2+0iMoyHAXpYqqLgKO5dncE/cfCp5/e+Xa/oWqpqvqLtx3YbUrlkAvQFUPqOpaz/IJYDPup8fLYltUVU96VgM9L6UMtgVARMKAbsD7uTaXybacQ5lqi4iE4P4B+AGAqmaoajLF0A5fSQTnGsqirKmtnucsPP/W8mwvE+0TkQZAK9y/pMtkWzynUuKBw8BcVS2zbQHeAJ4AXLm2ldW2KPCDiKzxDEkDZa8tjYAk4EPP6br3RSSYYmiHrySCAg1lUYaV+vaJSCXga+BhVU09X1Uv20pNW1Q1W1WjcD8F305ErjlP9VLbFhHpDhxW1TUF3cXLtlLRFo+Oqtoa94jG/xCR689Tt7S2JQD36eDxqtoKOIX7VNC5FFk7fCURXC5DWRw6Mzqr59/Dnu2lun0iEog7CXyqqv/zbC6TbTnD02VfCHShbLalI9BDRH7Ffar0JhH5hLLZFlR1v+ffw8A3uE+RlLW2JAKJnl4mwFTcicHxdvhKIijIcBdlwXTgXs/yvcC0XNv7i0h5EWmIe36HVSUQXz4iIrjPeW5W1f/kKiqLbakpIlU9yxWBm4EtlMG2qOr/U9UwVW2A+//DfFW9mzLYFhEJFpHKZ5aBW4ANlLG2qOpBYK+INPVs6gRsojjaUdJXyYvrhXsoi224r6w/XdLxFCDez3EPx52JO/PfD1QHfgS2e/4NzVX/aU/btgJdSzr+XHFdh7u7+jMQ73ndVkbbEgGs87RlA/CMZ3uZa0uedt3A73cNlbm24D63vt7z2njm/3cZbUsUEOf5G/sWqFYc7bAhJowxxsf5yqkhY4wx52CJwBhjfJwlAmOM8XGWCIwxxsdZIjDGGB9nicAYY3ycJQJjjPFx/x+4xEMch/T0ZgAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def draw_line(plt, epoch_list, data_list, color, label, max_marker=None):\n",
    "    plt.plot(epoch_list, data_list, color=color, label=label)\n",
    "    if max_marker is not None:\n",
    "        max_index = np.argmax(data_list)\n",
    "        val_str = \"{:.4f}\".format(data_list[max_index])\n",
    "        plt.plot(epoch_list[max_index],data_list[max_index], color=color, marker=max_marker)\n",
    "        plt.annotate(val_str,xytext=(-20, 10), textcoords='offset points',\n",
    "            xy=(epoch_list[max_index],data_list[max_index]), color=color)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "draw_line(plt, epoch_list, auc_pos_list, 'g', label=\"auc positive\", max_marker=\"^\")\n",
    "# draw_line(plt, epoch_list, auc_neg_list, 'b', label=\"auc negative\", max_marker=\"^\")\n",
    "# draw_line(plt, epoch_list, auc_score_list, 'r', label=\"auc negative - positive\", max_marker=\"^\")\n",
    "\n",
    "\n",
    "plt.ylabel('auc')\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)\n",
    "plt.yticks(np.arange(0, 1, step=0.1))\n",
    "plt.savefig(\"aggdv2.png\", dpi=400)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0.8683398488402397\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-b59a26ae6f15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc_pos_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc_neg_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: min() arg is an empty sequence"
     ],
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error"
    }
   ],
   "source": [
    "print(max(auc_pos_list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "ggd",
   "language": "python",
   "display_name": "GGD"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}