{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "Using backend: pytorch\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import copy\n",
    "import time\n",
    "import dgl\n",
    "from model import Model\n",
    "from utils import *\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import random\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy.io as sio\n",
    "import datetime\n",
    "from gcn import GCN\n",
    "from typing import List\n",
    "\n",
    "from dgl.nn.pytorch import SGConv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.cuda = True\n",
    "        \n",
    "        self.dataset = \"cora\"\n",
    "        self.device = \"cuda:0\"\n",
    "        self.embedding_dim = 64\n",
    "        \n",
    "        self.n_ggd_epochs = 600\n",
    "        self.patience = 500\n",
    "        self.batch_size = 300\n",
    "        self.eval_freq = 1\n",
    "        \n",
    "        self.n_hidden = 256\n",
    "        self.n_layers = 1\n",
    "        self.dropout = 0\n",
    "        self.proj_layers = 0\n",
    "        self.gnn_encoder = 'gcn'\n",
    "        self.num_hop = 10\n",
    "        self.ggd_lr = 1e-3\n",
    "        self.weight_decay = 0.\n",
    "        \n",
    "        self.subgraph_size = 4\n",
    "        self.auc_test_rounds = 64\n",
    "        \n",
    "        self.neg_batch_size = 1024\n",
    "args =  Args()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def aug_feature_dropout(input_feat, drop_percent=0.2):\n",
    "    # aug_input_feat = copy.deepcopy((input_feat.squeeze(0)))\n",
    "    aug_input_feat = copy.deepcopy(input_feat)\n",
    "    drop_feat_num = int(aug_input_feat.shape[1] * drop_percent)\n",
    "    drop_idx = random.sample([i for i in range(aug_input_feat.shape[1])], drop_feat_num)\n",
    "    aug_input_feat[:, drop_idx] = 0\n",
    "    \n",
    "    return aug_input_feat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Dataset: cora\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print('Dataset: {}'.format(args.dataset), flush=True)\n",
    "device = torch.device(args.device if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "batch_size = args.batch_size\n",
    "\n",
    "adj, features, labels, idx_train, idx_val, idx_test, ano_label, str_ano_label, attr_ano_label = load_mat(args.dataset)\n",
    "\n",
    "features, _ = preprocess_features(features)\n",
    "src, dst = np.nonzero(adj)\n",
    "g = dgl.graph((src, dst))\n",
    "g = dgl.add_self_loop(g)\n",
    "g.ndata['feat'] = torch.FloatTensor(features)\n",
    "g.ndata['label'] = torch.LongTensor(labels)\n",
    "n_edges = g.number_of_edges()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "nb_nodes = features.shape[0]\n",
    "ft_size = features.shape[1]\n",
    "nb_classes = labels.shape[1]\n",
    "\n",
    "# adj = normalize_adj(adj)\n",
    "# adj = (adj + sp.eye(adj.shape[0])).todense()\n",
    "# adj = torch.FloatTensor(adj[np.newaxis]).to(device)\n",
    "\n",
    "features = torch.FloatTensor(features).to(device)\n",
    "labels = torch.FloatTensor(labels).to(device)\n",
    "idx_train = torch.LongTensor(idx_train).to(device)\n",
    "idx_val = torch.LongTensor(idx_val).to(device)\n",
    "idx_test = torch.LongTensor(idx_test).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create GGD model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "gamma = 0\n",
      "0 0.8459603857180089\n",
      "1 0.8503101381287465\n",
      "2 0.8550169403179567\n",
      "3 0.8644513943184781\n",
      "4 0.8476987229606462\n",
      "gamma = 0.05\n",
      "0 0.8785691946833463\n",
      "1 0.8774224654678133\n",
      "2 0.8627182694813655\n",
      "3 0.8687464164712014\n",
      "4 0.8689236382590565\n",
      "gamma = 0.07\n",
      "0 0.8671957258274694\n",
      "1 0.8730179827990617\n",
      "2 0.8769012249152984\n",
      "3 0.8801563721657544\n",
      "4 0.8709903570497786\n",
      "gamma = 0.1\n",
      "0 0.8723794631222309\n",
      "1 0.8644123012770394\n",
      "2 0.8676075058639563\n",
      "3 0.8659629919207715\n",
      "4 0.86886630179828\n",
      "gamma = 0.2\n",
      "0 0.8797836851707064\n",
      "1 0.8678759447485015\n",
      "2 0.8659343236903831\n",
      "3 0.8655433932759968\n",
      "4 0.8649622100599427\n",
      "gamma = 0.3\n",
      "0 0.8568751628876726\n",
      "1 0.8593979671618452\n",
      "2 0.8670393536617148\n",
      "3 0.8601198853270784\n",
      "4 0.8645139431847797\n",
      "gamma = 0.4\n",
      "0 0.8475293197810788\n",
      "1 0.8634740682825125\n",
      "2 0.8532473286421685\n",
      "3 0.8656241855616367\n",
      "4 0.8699765441751367\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:23<00:00, 25.16it/s, loss=0.515]\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:23<00:00, 26.01it/s, loss=0.522]\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:21<00:00, 27.49it/s, loss=0.462]\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:23<00:00, 25.84it/s, loss=0.442]\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:23<00:00, 25.91it/s, loss=0.492]\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:22<00:00, 26.24it/s, loss=0.345]\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:22<00:00, 26.27it/s, loss=0.362]\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:22<00:00, 26.35it/s, loss=0.353]\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:22<00:00, 26.89it/s, loss=0.377]\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:22<00:00, 27.22it/s, loss=0.37]\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:21<00:00, 27.36it/s, loss=0.372]\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:21<00:00, 27.59it/s, loss=0.37]\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:21<00:00, 27.37it/s, loss=0.374]\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:21<00:00, 27.63it/s, loss=0.362]\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:21<00:00, 28.09it/s, loss=0.35]\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:21<00:00, 27.31it/s, loss=0.319]\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:21<00:00, 27.51it/s, loss=0.382]\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:20<00:00, 29.45it/s, loss=0.373]\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:20<00:00, 29.41it/s, loss=0.345]\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:20<00:00, 29.42it/s, loss=0.387]\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:20<00:00, 29.96it/s, loss=0.408]\n",
      "Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:19<00:00, 30.11it/s, loss=0.4]\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:20<00:00, 29.66it/s, loss=0.416]\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:20<00:00, 29.46it/s, loss=0.379]\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:20<00:00, 29.62it/s, loss=0.39]\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:20<00:00, 29.29it/s, loss=0.442]\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:19<00:00, 31.06it/s, loss=0.455]\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:19<00:00, 31.20it/s, loss=0.426]\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:19<00:00, 31.39it/s, loss=0.449]\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:19<00:00, 31.51it/s, loss=0.445]\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:18<00:00, 31.59it/s, loss=0.484]\n",
      "Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:19<00:00, 31.54it/s, loss=0.45]\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:18<00:00, 31.79it/s, loss=0.448]\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:18<00:00, 31.95it/s, loss=0.459]\n",
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:18<00:00, 32.28it/s, loss=0.399]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_hidden):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.bilinear = nn.Bilinear(n_hidden, n_hidden, 1)\n",
    "        for m in self.modules():\n",
    "            self.weights_init(m)\n",
    "\n",
    "    def weights_init(self, m):\n",
    "        if isinstance(m, nn.Bilinear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, features, summary):\n",
    "        s = self.bilinear(features, summary)\n",
    "        return s\n",
    "\n",
    "# class DiscriminatorCos(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(DiscriminatorCos, self).__init__()\n",
    "#         self.cos = torch.nn.CosineSimilarity(dim=1, eps=1e-06)\n",
    "# \n",
    "#     def forward(self, features, summary):\n",
    "#         print(features.shape)\n",
    "#         print(summary.shape)\n",
    "#         s = self.cos(features, summary)\n",
    "#         \n",
    "#         return torch.unsqueeze(s, 0)\n",
    "    \n",
    "\n",
    "class GraphSampler(torch.nn.Module):\n",
    "    def __init__(self, graph, n_nodes=4):\n",
    "        super(GraphSampler, self).__init__()\n",
    "        self.g = graph\n",
    "        \n",
    "        indices_list = []\n",
    "        probs_list = []\n",
    "        \n",
    "        A = self.g.adjacency_matrix()\n",
    "        for i in range(self.g.num_nodes()):\n",
    "            row = A[i]._indices()\n",
    "            size = row.size()[1]\n",
    "            tensor_ones = torch.ones(size)\n",
    "            indices = torch.cat([tensor_ones.unsqueeze(0) * i, row], dim=0)\n",
    "            indices_list.append(indices)\n",
    "            if size < n_nodes: \n",
    "                probs_list.append(tensor_ones)\n",
    "            else:\n",
    "                dropout_prob = n_nodes / size\n",
    "                probs_list.append(tensor_ones * dropout_prob)\n",
    "        probs = torch.cat(probs_list)\n",
    "        self.sampler = torch.distributions.bernoulli.Bernoulli(probs=probs.to(self.g.device))\n",
    "        self.indices = torch.cat(indices_list, dim=1).to(torch.int32).to(self.g.device)\n",
    "        \n",
    "    def sample(self):\n",
    "        new_indices = torch.masked_select(\n",
    "            self.indices, \n",
    "            self.sampler.sample().to(torch.bool)\n",
    "        ).reshape((2, -1))\n",
    "        graph = dgl.graph((new_indices[0, :], new_indices[1, :]), num_nodes= self.g.num_nodes())\n",
    "        if 'feat' in self.g.ndata:\n",
    "            graph.ndata['feat'] = self.g.ndata['feat']\n",
    "        if 'label' in self.g.ndata:\n",
    "            graph.ndata['label'] = self.g.ndata['label']\n",
    "        return dgl.add_self_loop(graph)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, g, in_feats, n_hidden, n_layers, activation, dropout, gnn_encoder, k=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.g = g\n",
    "        self.gnn_encoder = gnn_encoder\n",
    "        if gnn_encoder == 'gcn':\n",
    "            self.conv = GCN(g, in_feats, n_hidden, n_hidden, n_layers, activation, dropout)\n",
    "        elif gnn_encoder == 'sgc':\n",
    "            self.conv = SGConv(in_feats, n_hidden, k=10, cached=True)\n",
    "\n",
    "    def forward(self, features):\n",
    "        if self.gnn_encoder == 'gcn':\n",
    "            features = self.conv(features)\n",
    "        elif self.gnn_encoder == 'sgc':\n",
    "            features = self.conv(self.g, features)\n",
    "        return features\n",
    "class GraphLocalGraphPooling(nn.Module):\n",
    "    def __init__(self, g, n_hop):\n",
    "        # TODO: Simulate random walk (randomly drop some subgraph)\n",
    "        super(GraphLocalGraphPooling, self).__init__()\n",
    "        A = g.adjacency_matrix().to_dense() \n",
    "        A = A + torch.eye(A.shape[0])\n",
    "        A_n = A\n",
    "        for i in range(n_hop):\n",
    "            A_n =  torch.matmul(A_n, A)\n",
    "        # TODO: Check matrix situation (sym, factor\n",
    "        A = torch.sign(A_n)\n",
    "        self.A = torch.matmul(torch.diag(1/torch.sum(A, dim=1)), A)\n",
    "        self.A = self.A.cuda()\n",
    "    def forward(self, feature):\n",
    "        # feature: [n_nodes, n_features]\n",
    "        feature = torch.matmul(self.A, feature)\n",
    "        return feature\n",
    "\n",
    "\n",
    "class GGD_Anomaly(nn.Module):\n",
    "    def __init__(self, g, in_feats, n_hidden, n_layers, activation, dropout, proj_layers, gnn_encoder, num_hop, subgraph_size, sampler=None):\n",
    "        super(GGD_Anomaly, self).__init__()\n",
    "        self.g = g\n",
    "        self.sampler = sampler\n",
    "        self.encoder = Encoder(g, in_feats, n_hidden, n_layers, activation, dropout, gnn_encoder, num_hop)\n",
    "        self.discriminator = Discriminator(n_hidden)\n",
    "        # self.discriminator = DiscriminatorCos()\n",
    "        self.graph_average_pooling = lambda x: x\n",
    "        if subgraph_size > 0:\n",
    "            self.graph_average_pooling = GraphLocalGraphPooling(g, subgraph_size)\n",
    "                \n",
    "        self.graph_conv_layers = self.encoder.conv.layers\n",
    "        self.mlp = torch.nn.ModuleList()\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        for i in range(proj_layers):\n",
    "            self.mlp.append(nn.Linear(n_hidden, n_hidden))\n",
    "        # GGD\n",
    "        self.lin = nn.Linear(n_hidden, n_hidden)\n",
    "    def forward(self, features):\n",
    "        \n",
    "        if self.sampler is not None:\n",
    "            # sample from graph\n",
    "            self.encoder.conv.g = self.sampler.sample()\n",
    "            \n",
    "            \n",
    "        features = self.dropout(features)\n",
    "        embedding_node = features\n",
    "        for i, graph_conv_layer in enumerate(self.graph_conv_layers):\n",
    "             embedding_node = graph_conv_layer._activation(torch.matmul(embedding_node, graph_conv_layer.weight) + graph_conv_layer.bias)\n",
    "\n",
    "\n",
    "        embedding_graph_pos = self.encoder(features)\n",
    "        # avg pooling \n",
    "        embedding_graph_readout = self.graph_average_pooling(embedding_node)\n",
    "        # Add skip connection\n",
    "        embedding_graph_proj = (embedding_graph_pos + embedding_graph_readout) / 2\n",
    "        # Positive branch of Anomaly\n",
    "        predicted_score_pos = self.discriminator(embedding_node, embedding_graph_proj)\n",
    "        # change shape from [n_nodes, 1] to [1, n_nodes]\n",
    "        predicted_score_pos = torch.swapaxes(predicted_score_pos, 0, 1)\n",
    "        \n",
    "        # Negative branch of Anomaly\n",
    "        perm = torch.randperm(self.g.number_of_nodes())\n",
    "        embedding_node_neg = embedding_node[perm]\n",
    "        predicted_score_neg = self.discriminator(embedding_node_neg, embedding_graph_proj)\n",
    "        predicted_score_neg = torch.swapaxes(predicted_score_neg, 0, 1)\n",
    "        \n",
    "        # ggd \n",
    "        ggd_score_pos = self.lin(embedding_graph_proj).sum(1).unsqueeze(0)\n",
    "        \n",
    "        embedding_graph_neg = self.encoder(features[perm])\n",
    "        ggd_score_neg = self.lin(embedding_graph_neg).sum(1).unsqueeze(0)\n",
    "        \n",
    "        if self.sampler is not None:\n",
    "            self.encoder.conv.g = self.g\n",
    "        return predicted_score_pos, predicted_score_neg, ggd_score_pos, ggd_score_neg\n",
    "g = g.to(device)\n",
    "# Create GGD model\n",
    "\n",
    "# gamma = 0.07\n",
    "for gamma in [0, 0.05, 0.07, 0.1, 0.2, 0.3, 0.4]:\n",
    "    print(\"gamma =\", gamma)\n",
    "    for i in range(5):\n",
    "        ggd = GGD_Anomaly(\n",
    "            g,\n",
    "            ft_size,\n",
    "            args.n_hidden,\n",
    "            args.n_layers,\n",
    "            nn.PReLU(args.n_hidden),\n",
    "            args.dropout,\n",
    "            args.proj_layers,\n",
    "            args.gnn_encoder,\n",
    "            args.num_hop,\n",
    "            args.subgraph_size, \n",
    "            # sampler=GraphSampler(g, n_nodes=4)\n",
    "        )\n",
    "        if args.cuda:\n",
    "            ggd.cuda()\n",
    "        \n",
    "        #%%\n",
    "        \n",
    "        \n",
    "        ggd_optimizer = torch.optim.Adam(ggd.parameters(),\n",
    "                                         lr=args.ggd_lr,\n",
    "                                         weight_decay=args.weight_decay)\n",
    "        b_xent = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        #%% md\n",
    "        \n",
    "        # train GGD\n",
    "        \n",
    "        #%%\n",
    "        \n",
    "        cnt_wait = 0\n",
    "        best = 1e9\n",
    "        best_t = 0\n",
    "        counts = 0\n",
    "        avg_time = 0\n",
    "        dur = []\n",
    "        loss_list = []\n",
    "        \n",
    "        tag = str(datetime.datetime.now().strftime(\"%m-%d %H%M%S\"))\n",
    "        # print(\"Memory beg:\", torch.cuda.memory_allocated(device) / 1024 / 1024)\n",
    "        \n",
    "        epoch_list = []\n",
    "        auc_score_list = []\n",
    "        auc_pos_list = []\n",
    "        auc_neg_list = []\n",
    "        pos_std = []\n",
    "        neg_std = []\n",
    "        score_std = []\n",
    "        label_positive = torch.zeros(1, g.number_of_nodes()).cuda()\n",
    "        label_negative = torch.ones(1, g.number_of_nodes()).cuda()\n",
    "        with tqdm(total=args.n_ggd_epochs) as pbar:\n",
    "            pbar.set_description('Training')\n",
    "            for epoch in range(args.n_ggd_epochs):\n",
    "                if epoch % args.eval_freq == 0:\n",
    "                    ggd.eval()\n",
    "                    with torch.no_grad():\n",
    "                        pos_prob_list = []\n",
    "                        neg_prob_list = []\n",
    "                        # for i in range(args.auc_test_rounds):\n",
    "                        #     feature_dropout = aug_feature_dropout(features, 0.2)\n",
    "                        #     pos_prob_list.append(ggd(feature_dropout).detach()[0])\n",
    "                        #     perm = torch.randperm(g.number_of_nodes())\n",
    "                        #     inverse_perm = torch.argsort(perm)\n",
    "                        #     features_perm = feature_dropout[perm]\n",
    "                        #     neg_prob_list.append(ggd(features_perm).detach()[0][inverse_perm])\n",
    "                        pos_prob_list.append(ggd(features)[0].detach()[0])\n",
    "                        # perm = torch.randperm(g.number_of_nodes())\n",
    "                        # inverse_perm = torch.argsort(perm)\n",
    "                        # features_perm = features[perm]\n",
    "                        # neg_prob_list.append(ggd(features_perm).detach()[0])\n",
    "                        # neg_prob_list.append(ggd(features_perm).detach()[0][inverse_perm])\n",
    "                        \n",
    "                        pos_prob = torch.mean(torch.stack(pos_prob_list), axis=0)\n",
    "                        # neg_prob = torch.mean(torch.stack(neg_prob_list), axis=0)\n",
    "                        # ano_score = (neg_prob - pos_prob).cpu().numpy()\n",
    "                        epoch_list.append(epoch)\n",
    "                        # auc_score_list.append(roc_auc_score(ano_label, ano_score))\n",
    "                        auc_pos_list.append(roc_auc_score(ano_label, pos_prob.cpu().numpy()))\n",
    "                        # auc_neg_list.append(roc_auc_score(ano_label, neg_prob.cpu().numpy()))\n",
    "                        pos_std.append(np.std(pos_prob.cpu().numpy()))\n",
    "                        # neg_std.append(np.std(neg_prob.cpu().numpy()))\n",
    "                        # score_std.append(np.std(ano_score))\n",
    "                \n",
    "                t0 = time.time()\n",
    "                ggd.train()\n",
    "                if epoch >= 3:\n",
    "                    t0 = time.time()\n",
    "                    \n",
    "                ggd_optimizer.zero_grad()\n",
    "                # Positive\n",
    "                # training_features = aug_feature_dropout(features, drop_percent=0.2)\n",
    "                training_features = features\n",
    "                s_positive, s_negative, ggd_score_pos, ggd_score_neg = ggd(training_features)\n",
    "                loss_positive = b_xent(s_positive, label_positive)\n",
    "                loss_negative = b_xent(s_negative, label_negative)\n",
    "                loss_anomaly = loss_positive + loss_negative\n",
    "                loss_ggd = b_xent(ggd_score_pos, label_positive) + b_xent(ggd_score_neg, label_negative)\n",
    "                loss = (1-gamma) * loss_anomaly + gamma * loss_ggd\n",
    "                \n",
    "                loss.backward()\n",
    "                ggd_optimizer.step()\n",
    "            \n",
    "                comp_time = time.time() - t0\n",
    "                if loss < best:\n",
    "                    best = loss\n",
    "                    best_t = epoch\n",
    "                    cnt_wait = 0\n",
    "                    # torch.save(ggd.state_dict(), 'checkpoints_ggd/best_ggd' + tag + '.pkl')\n",
    "                else:\n",
    "                    cnt_wait += 1\n",
    "            \n",
    "                if cnt_wait == args.patience:\n",
    "                    print('Early stopping!')\n",
    "                    break\n",
    "            \n",
    "                if epoch >= 3:\n",
    "                    dur.append(time.time() - t0)\n",
    "                \n",
    "                pbar.set_postfix(loss=loss.item())\n",
    "                pbar.update(1)\n",
    "                loss_list.append((loss.detach().cpu().item(), loss_positive.detach().cpu().item(), loss_negative.detach().cpu().item()))\n",
    "                avg_time += comp_time\n",
    "                counts += 1\n",
    "        \n",
    "        print(i, max(auc_pos_list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# def draw_line(plt, epoch_list, data_list, color, label, max_marker=None):\n",
    "#     plt.plot(epoch_list, data_list, color=color, label=label)\n",
    "#     if max_marker is not None:\n",
    "#         max_index = np.argmax(data_list)\n",
    "#         val_str = \"{:.4f}\".format(data_list[max_index])\n",
    "#         plt.plot(epoch_list[max_index],data_list[max_index], color=color, marker=max_marker)\n",
    "#         plt.annotate(val_str,xytext=(-20, 10), textcoords='offset points',\n",
    "#             xy=(epoch_list[max_index],data_list[max_index]), color=color)\n",
    "#     \n",
    "# import matplotlib.pyplot as plt\n",
    "# # draw_line(plt, epoch_list, auc_score_list, 'r', label=\"auc negative - positive\", max_marker=\"^\")\n",
    "# draw_line(plt, epoch_list, auc_pos_list, 'g', label=\"auc positive\", max_marker=\"^\")\n",
    "# # draw_line(plt, epoch_list, auc_neg_list, 'b', label=\"auc negative\", max_marker=\"^\")\n",
    "# \n",
    "# \n",
    "# plt.ylabel('auc')\n",
    "# plt.legend()\n",
    "# plt.ylim(0, 1)\n",
    "# plt.yticks(np.arange(0, 1, step=0.1))\n",
    "# plt.savefig(\"aggdv2.png\", dpi=400)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0.8699765441751367\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(max(auc_pos_list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(indices=tensor([[   0,    0,    0,  ..., 2705, 2706, 2707],\n                       [ 294,  479,  633,  ..., 2705, 2706, 2707]]),\n       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n       size=(2708, 2708), nnz=14314, layout=torch.sparse_coo)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 11
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "ggd",
   "language": "python",
   "display_name": "GGD"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}