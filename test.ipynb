{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "import dgl\n",
    "from model import Model\n",
    "from utils import *\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import random\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy.io as sio\n",
    "import datetime\n",
    "from ggd import *\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.cuda = True\n",
    "        \n",
    "        self.dataset = \"cora\"\n",
    "        self.device = \"cuda:0\"\n",
    "        self.embedding_dim = 64\n",
    "        \n",
    "        self.n_ggd_epochs = 100\n",
    "        self.patience = 500\n",
    "        self.batch_size = 300\n",
    "        \n",
    "        self.n_hidden = 256\n",
    "        self.n_layers = 1\n",
    "        self.dropout = 0\n",
    "        self.proj_layers = 1\n",
    "        self.gnn_encoder = 'gcn'\n",
    "        self.num_hop = 10\n",
    "        self.ggd_lr = 1e-3\n",
    "        self.weight_decay = 0.\n",
    "        \n",
    "        self.auc_test_rounds = 256\n",
    "args =  Args()\n",
    "\n",
    "def aug_feature_dropout(input_feat, drop_percent=0.2):\n",
    "    # aug_input_feat = copy.deepcopy((input_feat.squeeze(0)))\n",
    "    aug_input_feat = copy.deepcopy(input_feat)\n",
    "    drop_feat_num = int(aug_input_feat.shape[1] * drop_percent)\n",
    "    drop_idx = random.sample([i for i in range(aug_input_feat.shape[1])], drop_feat_num)\n",
    "    aug_input_feat[:, drop_idx] = 0\n",
    "    \n",
    "    return aug_input_feat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Dataset: cora\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print('Dataset: {}'.format(args.dataset), flush=True)\n",
    "device = torch.device(args.device if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "batch_size = args.batch_size\n",
    "\n",
    "adj, features, labels, idx_train, idx_val, idx_test, ano_label, str_ano_label, attr_ano_label = load_mat(args.dataset)\n",
    "\n",
    "features, _ = preprocess_features(features)\n",
    "dgl_graph = adj_to_dgl_graph(adj)\n",
    "src, dst = np.nonzero(adj)\n",
    "g = dgl.graph((src, dst))\n",
    "g.ndata['feat'] = torch.FloatTensor(features)\n",
    "g.ndata['label'] = torch.LongTensor(labels)\n",
    "n_edges = g.number_of_edges()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "nb_nodes = features.shape[0]\n",
    "ft_size = features.shape[1]\n",
    "nb_classes = labels.shape[1]\n",
    "\n",
    "# adj = normalize_adj(adj)\n",
    "# adj = (adj + sp.eye(adj.shape[0])).todense()\n",
    "# adj = torch.FloatTensor(adj[np.newaxis]).to(device)\n",
    "\n",
    "features = torch.FloatTensor(features).to(device)\n",
    "labels = torch.FloatTensor(labels).to(device)\n",
    "idx_train = torch.LongTensor(idx_train).to(device)\n",
    "idx_val = torch.LongTensor(idx_val).to(device)\n",
    "idx_test = torch.LongTensor(idx_test).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create GGD model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11160\\1898879524.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Create GGD model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m ggd = GGD(g,\n\u001b[0m\u001b[0;32m      4\u001b[0m           \u001b[0mft_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m           \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GGD' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'GGD' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "g = g.to(device)\n",
    "# Create GGD model\n",
    "ggd = GGD(g,\n",
    "          ft_size,\n",
    "          args.n_hidden,\n",
    "          args.n_layers,\n",
    "          nn.PReLU(args.n_hidden),\n",
    "          args.dropout,\n",
    "          args.proj_layers,\n",
    "          args.gnn_encoder,\n",
    "          args.num_hop)\n",
    "\n",
    "if args.cuda:\n",
    "    ggd.cuda()\n",
    "\n",
    "ggd_optimizer = torch.optim.Adam(ggd.parameters(),\n",
    "                                 lr=args.ggd_lr,\n",
    "                                 weight_decay=args.weight_decay)\n",
    "b_xent = nn.BCEWithLogitsLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# train GGD\n",
    "cnt_wait = 0\n",
    "best = 1e9\n",
    "best_t = 0\n",
    "counts = 0\n",
    "avg_time = 0\n",
    "dur = []\n",
    "\n",
    "tag = str(datetime.datetime.now().strftime(\"%m-%d %H%M%S\"))\n",
    "print(\"Memory beg:\", torch.cuda.memory_allocated(device) / 1024 / 1024)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epoch_list = []\n",
    "auc_score_list = []\n",
    "auc_pos_list = []\n",
    "auc_neg_list = []\n",
    "pos_std = []\n",
    "neg_std = []\n",
    "score_std = []\n",
    "\n",
    "for epoch in range(args.n_ggd_epochs):\n",
    "    if epoch % 10 == 0:\n",
    "        # Evaluation\n",
    "        ggd.eval()\n",
    "        with torch.no_grad():\n",
    "            pos_prob_list = []\n",
    "            neg_prob_list = []\n",
    "            for i in range(args.auc_test_rounds):\n",
    "                feature_dropout = aug_feature_dropout(features, 0.2)\n",
    "                pos_prob_list.append(ggd.forward_predict(features, False).detach())\n",
    "                neg_prob_list.append(ggd.forward_predict(features, True).detach())\n",
    "            pos_prob = torch.mean(torch.stack(pos_prob_list), axis=0)\n",
    "            neg_prob = torch.mean(torch.stack(neg_prob_list), axis=0)\n",
    "            ano_score = (neg_prob - pos_prob).cpu().numpy()\n",
    "            epoch_list.append(epoch)\n",
    "            auc_score_list.append(roc_auc_score(ano_label, ano_score))\n",
    "            auc_pos_list.append(roc_auc_score(ano_label, 1 - pos_prob.cpu().numpy()))\n",
    "            auc_neg_list.append(roc_auc_score(ano_label, neg_prob.cpu().numpy()))\n",
    "            pos_std.append(np.std(pos_prob.cpu().numpy()))\n",
    "            neg_std.append(np.std(neg_prob.cpu().numpy()))\n",
    "            score_std.append(np.std(ano_score))\n",
    "    t0 = time.time()\n",
    "    ggd.train()\n",
    "    if epoch >= 3:\n",
    "        t0 = time.time()\n",
    "    ggd_optimizer.zero_grad()\n",
    "    lbl_1 = torch.zeros(1, g.number_of_nodes())\n",
    "    lbl_2 = torch.ones(1, g.number_of_nodes())\n",
    "    lbl = torch.cat((lbl_1, lbl_2), 1).cuda()\n",
    "    # import pdb; pdb.set_trace()\n",
    "    aug_feat = aug_feature_dropout(features, 0.2)\n",
    "    loss = ggd(aug_feat.cuda(), lbl, b_xent)\n",
    "    loss.backward()\n",
    "    ggd_optimizer.step()\n",
    "\n",
    "    comp_time = time.time() - t0\n",
    "    # print('{} seconds'.format(comp_time))\n",
    "\n",
    "    if loss < best:\n",
    "        best = loss\n",
    "        best_t = epoch\n",
    "        cnt_wait = 0\n",
    "        torch.save(ggd.state_dict(), 'checkpoints_ggd/best_ggd' + tag + '.pkl')\n",
    "    else:\n",
    "        cnt_wait += 1\n",
    "\n",
    "    if cnt_wait == args.patience:\n",
    "        print('Early stopping!')\n",
    "        break\n",
    "\n",
    "    if epoch >= 3:\n",
    "        dur.append(time.time() - t0)\n",
    "\n",
    "    print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | \"\n",
    "          \"ETputs(KTEPS) {:.2f}\".format(epoch, np.mean(dur), loss.item(),\n",
    "                                        n_edges / np.mean(dur) / 1000))\n",
    "\n",
    "    avg_time += comp_time\n",
    "    counts += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# epoch_list \n",
    "# auc_score_list \n",
    "# auc_pos_list \n",
    "# auc_neg_list \n",
    "# pos_std \n",
    "# neg_std \n",
    "# score_std \n",
    "print(epoch_list)\n",
    "print(auc_score_list)\n",
    "print(auc_pos_list)\n",
    "print(auc_neg_list)\n",
    "print(pos_std)\n",
    "print(neg_std)\n",
    "print(score_std)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(epoch_list, auc_score_list, 'r', label=\"roc_auc_score(ano_label, negative - positive)\")\n",
    "plt.plot(epoch_list, auc_pos_list, 'g', label=\"roc_auc_score(ano_label, positive)\")\n",
    "plt.plot(epoch_list, auc_neg_list, 'b', label=\"roc_auc_score(ano_label, negative)\")\n",
    "plt.ylabel('auc')\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)\n",
    "plt.yticks(np.arange(0, 1, step=0.1))\n",
    "plt.savefig(\"anomyggd_dropout.png\", dpi=400)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "neg_pred = torch.cat(neg_prob_list, dim=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean = torch.mean(neg_pred).detach().cpu().item()\n",
    "std = torch.std(neg_pred).detach().cpu().item()\n",
    "\n",
    "dummy_score = np.random.normal(mean, std, size=ano_label.size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "roc_auc_score(ano_label, neg_prob.cpu().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_feature = torch.mean(features, 0).detach().cpu()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(64):\n",
    "    rand_feature = (torch.rand(features.shape) < mean_feature).to(torch.float32)\n",
    "    score_zero = ggd.forward_predict(rand_feature.to(device), False)\n",
    "    res.append(roc_auc_score(ano_label, score_zero.detach().cpu().numpy()))\n",
    "res = np.array(res)\n",
    "print(\"mean:\", np.mean(res), \" std:\", np.std(res))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "ggd",
   "language": "python",
   "display_name": "GGD"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}