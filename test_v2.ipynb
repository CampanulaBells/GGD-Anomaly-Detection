{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "import dgl\n",
    "from model import Model\n",
    "from utils import *\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import random\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy.io as sio\n",
    "import datetime\n",
    "from ggda import *\n",
    "from typing import List\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.cuda = True\n",
    "        \n",
    "        self.dataset = \"cora\"\n",
    "        self.device = \"cuda:0\"\n",
    "        self.embedding_dim = 64\n",
    "        \n",
    "        self.n_ggd_epochs = 600\n",
    "        self.patience = 500\n",
    "        self.batch_size = 300\n",
    "        self.eval_freq = 1\n",
    "        \n",
    "        self.n_hidden = 256\n",
    "        self.n_layers = 1\n",
    "        self.dropout = 0\n",
    "        self.proj_layers = 0\n",
    "        self.gnn_encoder = 'gcn'\n",
    "        self.num_hop = 10\n",
    "        self.ggd_lr = 1e-3\n",
    "        self.weight_decay = 0.\n",
    "        \n",
    "        self.subgraph_size = 4\n",
    "        self.auc_test_rounds = 64\n",
    "        \n",
    "        self.neg_batch_size = 1024\n",
    "args =  Args()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def aug_feature_dropout(input_feat, drop_percent=0.2):\n",
    "    # aug_input_feat = copy.deepcopy((input_feat.squeeze(0)))\n",
    "    aug_input_feat = copy.deepcopy(input_feat)\n",
    "    drop_feat_num = int(aug_input_feat.shape[1] * drop_percent)\n",
    "    drop_idx = random.sample([i for i in range(aug_input_feat.shape[1])], drop_feat_num)\n",
    "    aug_input_feat[:, drop_idx] = 0\n",
    "    \n",
    "    return aug_input_feat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Dataset: cora\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "G:\\GNN\\Graph-Group-Discrimination-main\\venv\\lib\\site-packages\\dgl\\base.py:45: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print('Dataset: {}'.format(args.dataset), flush=True)\n",
    "device = torch.device(args.device if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "batch_size = args.batch_size\n",
    "\n",
    "adj, features, labels, idx_train, idx_val, idx_test, ano_label, str_ano_label, attr_ano_label = load_mat(args.dataset)\n",
    "\n",
    "features, _ = preprocess_features(features)\n",
    "dgl_graph = adj_to_dgl_graph(adj)\n",
    "src, dst = np.nonzero(adj)\n",
    "g = dgl.graph((src, dst))\n",
    "g.ndata['feat'] = torch.FloatTensor(features)\n",
    "g.ndata['label'] = torch.LongTensor(labels)\n",
    "n_edges = g.number_of_edges()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "nb_nodes = features.shape[0]\n",
    "ft_size = features.shape[1]\n",
    "nb_classes = labels.shape[1]\n",
    "\n",
    "# adj = normalize_adj(adj)\n",
    "# adj = (adj + sp.eye(adj.shape[0])).todense()\n",
    "# adj = torch.FloatTensor(adj[np.newaxis]).to(device)\n",
    "\n",
    "features = torch.FloatTensor(features).to(device)\n",
    "labels = torch.FloatTensor(labels).to(device)\n",
    "idx_train = torch.LongTensor(idx_train).to(device)\n",
    "idx_val = torch.LongTensor(idx_val).to(device)\n",
    "idx_test = torch.LongTensor(idx_test).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create GGD model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_hidden):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.bilinear = nn.Bilinear(n_hidden, n_hidden, 1)\n",
    "        for m in self.modules():\n",
    "            self.weights_init(m)\n",
    "\n",
    "    def weights_init(self, m):\n",
    "        if isinstance(m, nn.Bilinear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, features, summary):\n",
    "        s = self.bilinear(features, summary)\n",
    "        return s\n",
    "\n",
    "# class DiscriminatorCos(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(DiscriminatorCos, self).__init__()\n",
    "#         self.cos = torch.nn.CosineSimilarity(dim=1, eps=1e-06)\n",
    "# \n",
    "#     def forward(self, features, summary):\n",
    "#         print(features.shape)\n",
    "#         print(summary.shape)\n",
    "#         s = self.cos(features, summary)\n",
    "#         \n",
    "#         return torch.unsqueeze(s, 0)\n",
    "    \n",
    "class GraphLocalGraphPooling(nn.Module):\n",
    "    def __init__(self, g, n_hop):\n",
    "        # TODO: Simulate random walk (randomly drop some subgraph)\n",
    "        super(GraphLocalGraphPooling, self).__init__()\n",
    "        A = g.adjacency_matrix().to_dense() \n",
    "        A = A + torch.eye(A.shape[0])\n",
    "        A_n = A\n",
    "        for i in range(n_hop):\n",
    "            A_n =  torch.matmul(A_n, A)\n",
    "        # TODO: Check matrix situation (sym, factor\n",
    "        A = torch.sign(A_n)\n",
    "        self.A = torch.matmul(torch.diag(1/torch.sum(A, dim=1)), A)\n",
    "        self.A = self.A.cuda()\n",
    "    def forward(self, feature):\n",
    "        # feature: [n_nodes, n_features]\n",
    "        feature = torch.matmul(self.A, feature)\n",
    "        return feature\n",
    "\n",
    "\n",
    "class GGD_Anomaly(nn.Module):\n",
    "    def __init__(self, g, in_feats, n_hidden, n_layers, activation, dropout, proj_layers, gnn_encoder, num_hop, subgraph_size):\n",
    "        super(GGD_Anomaly, self).__init__()\n",
    "        self.g = g\n",
    "        self.encoder = Encoder(g, in_feats, n_hidden, n_layers, activation, dropout, gnn_encoder, num_hop)\n",
    "        self.discriminator = Discriminator(n_hidden)\n",
    "        # self.discriminator = DiscriminatorCos()\n",
    "        self.graph_average_pooling = lambda x: x\n",
    "        if subgraph_size > 0:\n",
    "            self.graph_average_pooling = GraphLocalGraphPooling(g, subgraph_size)\n",
    "        \n",
    "        self.graph_conv_layers = self.encoder.conv.layers\n",
    "        self.mlp = torch.nn.ModuleList()\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        for i in range(proj_layers):\n",
    "            self.mlp.append(nn.Linear(n_hidden, n_hidden))\n",
    "            \n",
    "    def forward(self, features, index=None, randswap=False):\n",
    "        # features: [n_nodes, n_features]\n",
    "        # Can be seen as normal MLP input: batch_size, features\n",
    "        features = self.dropout(features)\n",
    "        if index is None:\n",
    "            embedding_node = features\n",
    "        else:\n",
    "            embedding_node = features[index]\n",
    "        for i, graph_conv_layer in enumerate(self.graph_conv_layers):\n",
    "             embedding_node = graph_conv_layer._activation(torch.matmul(embedding_node, graph_conv_layer.weight) + graph_conv_layer.bias)\n",
    "             # embedding_node = torch.nn.functional.relu(torch.matmul(embedding_node, graph_conv_layer.weight) + graph_conv_layer.bias)\n",
    "             # embedding_node = torch.matmul(embedding_node, graph_conv_layer.weight) + graph_conv_layer.bias\n",
    "\n",
    "        embedding_graph_proj = self.encoder(features)\n",
    "        # TEST: add skip connection\n",
    "        embedding_graph_proj = (embedding_graph_proj + self.graph_average_pooling(embedding_node)) / 2\n",
    "        if index is not None:\n",
    "            embedding_graph_proj = embedding_graph_proj[index]\n",
    "        # embedding_graph = self.encoder(features)\n",
    "        \n",
    "        # embedding_graph_proj = self.graph_average_pooling(embedding_graph)\n",
    "        # for i, linear in enumerate(self.mlp):\n",
    "        #     embedding_graph_proj = linear(embedding_graph_proj)\n",
    "            \n",
    "        # testing AVG pooling\n",
    "        # embedding_graph_proj = embedding_graph\n",
    "        # for i, linear in enumerate(self.mlp):\n",
    "        #     embedding_graph_proj = linear(embedding_graph_proj)\n",
    "        # embedding_graph_proj = self.graph_average_pooling(embedding_graph_proj)\n",
    "        if randswap:\n",
    "            embedding_node = embedding_node[torch.randperm(self.g.number_of_nodes())]\n",
    "        \n",
    "        predicted_score = self.discriminator(embedding_node, embedding_graph_proj)\n",
    "        # change shape from [n_nodes, 1] to [1, n_nodes]\n",
    "        predicted_score = torch.swapaxes(predicted_score, 0, 1)\n",
    "        return predicted_score\n",
    "g = g.to(device)\n",
    "# Create GGD model\n",
    "ggd = GGD_Anomaly(\n",
    "    g,\n",
    "    ft_size,\n",
    "    args.n_hidden,\n",
    "    args.n_layers,\n",
    "    nn.PReLU(args.n_hidden),\n",
    "    args.dropout,\n",
    "    args.proj_layers,\n",
    "    args.gnn_encoder,\n",
    "    args.num_hop,\n",
    "    args.subgraph_size\n",
    ")\n",
    "if args.cuda:\n",
    "    ggd.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "\n",
    "ggd_optimizer = torch.optim.Adam(ggd.parameters(),\n",
    "                                 lr=args.ggd_lr,\n",
    "                                 weight_decay=args.weight_decay)\n",
    "b_xent = nn.BCEWithLogitsLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "train GGD"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 600/600 [00:16<00:00, 35.55it/s, loss=0.608]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "cnt_wait = 0\n",
    "best = 1e9\n",
    "best_t = 0\n",
    "counts = 0\n",
    "avg_time = 0\n",
    "dur = []\n",
    "loss_list = []\n",
    "\n",
    "tag = str(datetime.datetime.now().strftime(\"%m-%d %H%M%S\"))\n",
    "# print(\"Memory beg:\", torch.cuda.memory_allocated(device) / 1024 / 1024)\n",
    "\n",
    "epoch_list = []\n",
    "auc_score_list = []\n",
    "auc_pos_list = []\n",
    "auc_neg_list = []\n",
    "pos_std = []\n",
    "neg_std = []\n",
    "score_std = []\n",
    "label_positive = torch.zeros(1, g.number_of_nodes()).cuda()\n",
    "label_negative = torch.ones(1, g.number_of_nodes()).cuda()\n",
    "with tqdm(total=args.n_ggd_epochs) as pbar:\n",
    "    pbar.set_description('Training')\n",
    "    for epoch in range(args.n_ggd_epochs):\n",
    "        if epoch % args.eval_freq == 0:\n",
    "            ggd.eval()\n",
    "            with torch.no_grad():\n",
    "                pos_prob_list = []\n",
    "                neg_prob_list = []\n",
    "                # for i in range(args.auc_test_rounds):\n",
    "                #     feature_dropout = aug_feature_dropout(features, 0.2)\n",
    "                #     pos_prob_list.append(ggd(feature_dropout).detach()[0])\n",
    "                #     perm = torch.randperm(g.number_of_nodes())\n",
    "                #     inverse_perm = torch.argsort(perm)\n",
    "                #     features_perm = feature_dropout[perm]\n",
    "                #     neg_prob_list.append(ggd(features_perm).detach()[0][inverse_perm])\n",
    "                pos_prob_list.append(ggd(features).detach()[0])\n",
    "                # perm = torch.randperm(g.number_of_nodes())\n",
    "                # inverse_perm = torch.argsort(perm)\n",
    "                # features_perm = features[perm]\n",
    "                # neg_prob_list.append(ggd(features_perm).detach()[0])\n",
    "                # neg_prob_list.append(ggd(features_perm).detach()[0][inverse_perm])\n",
    "                \n",
    "                pos_prob = torch.mean(torch.stack(pos_prob_list), axis=0)\n",
    "                # neg_prob = torch.mean(torch.stack(neg_prob_list), axis=0)\n",
    "                # ano_score = (neg_prob - pos_prob).cpu().numpy()\n",
    "                epoch_list.append(epoch)\n",
    "                # auc_score_list.append(roc_auc_score(ano_label, ano_score))\n",
    "                auc_pos_list.append(roc_auc_score(ano_label, pos_prob.cpu().numpy()))\n",
    "                # auc_neg_list.append(roc_auc_score(ano_label, neg_prob.cpu().numpy()))\n",
    "                pos_std.append(np.std(pos_prob.cpu().numpy()))\n",
    "                # neg_std.append(np.std(neg_prob.cpu().numpy()))\n",
    "                # score_std.append(np.std(ano_score))\n",
    "        \n",
    "        t0 = time.time()\n",
    "        ggd.train()\n",
    "        if epoch >= 3:\n",
    "            t0 = time.time()\n",
    "        ggd_optimizer.zero_grad()\n",
    "        # Positive\n",
    "        # training_features = aug_feature_dropout(features, drop_percent=0.2)\n",
    "        training_features = features\n",
    "        s_positive = ggd(training_features)\n",
    "        loss_positive = b_xent(s_positive, label_positive)\n",
    "        # Negative\n",
    "        \n",
    "        # perm = torch.randperm(g.number_of_nodes())\n",
    "        \n",
    "        # batch_perm = torch.randperm(g.number_of_nodes())\n",
    "        # j = 0\n",
    "        # loss_negative = 0\n",
    "        # while j * args.neg_batch_size < g.number_of_nodes():\n",
    "        #     loc_index = batch_perm[j * args.neg_batch_size:min(g.number_of_nodes(), (j + 1) * args.neg_batch_size)]\n",
    "        #     swap_index = torch.arange(0, g.number_of_nodes())\n",
    "        #     swap_index[loc_index] = perm[loc_index]\n",
    "        #     swap_index[perm[loc_index]] = loc_index\n",
    "        #     \n",
    "        #     s_negative = ggd(training_features[swap_index], loc_index)\n",
    "        #     loss_negative += b_xent(s_negative, label_negative[:,j * args.neg_batch_size:min(g.number_of_nodes(), (j + 1) * args.neg_batch_size)])\n",
    "        #     j = j + 1\n",
    "        # features_perm = training_features[perm]\n",
    "        # s_negative = ggd(features_perm)\n",
    "        s_negative = ggd(training_features, randswap=True)\n",
    "        loss_negative = b_xent(s_negative, label_negative)\n",
    "        \n",
    "        loss = loss_positive + loss_negative\n",
    "        \n",
    "        loss.backward()\n",
    "        ggd_optimizer.step()\n",
    "    \n",
    "        comp_time = time.time() - t0\n",
    "        if loss < best:\n",
    "            best = loss\n",
    "            best_t = epoch\n",
    "            cnt_wait = 0\n",
    "            # torch.save(ggd.state_dict(), 'checkpoints_ggd/best_ggd' + tag + '.pkl')\n",
    "        else:\n",
    "            cnt_wait += 1\n",
    "    \n",
    "        if cnt_wait == args.patience:\n",
    "            print('Early stopping!')\n",
    "            break\n",
    "    \n",
    "        if epoch >= 3:\n",
    "            dur.append(time.time() - t0)\n",
    "        \n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "        pbar.update(1)\n",
    "        # print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | \"\n",
    "        #       \"ETputs(KTEPS) {:.2f}\".format(epoch, np.mean(dur), loss.item(),\n",
    "        #                                     n_edges / np.mean(dur) / 1000))\n",
    "        \n",
    "        loss_list.append((loss.detach().cpu().item(), loss_positive.detach().cpu().item(), loss_negative.detach().cpu().item()))\n",
    "        avg_time += comp_time\n",
    "        counts += 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visualization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def draw_line(plt, epoch_list, data_list, color, label, max_marker=None):\n",
    "    plt.plot(epoch_list, data_list, color=color, label=label)\n",
    "    if max_marker is not None:\n",
    "        max_index = np.argmax(data_list)\n",
    "        val_str = \"{:.4f}\".format(data_list[max_index])\n",
    "        plt.plot(epoch_list[max_index],data_list[max_index], color=color, marker=max_marker)\n",
    "        plt.annotate(val_str,xytext=(-20, 10), textcoords='offset points',\n",
    "            xy=(epoch_list[max_index],data_list[max_index]), color=color)\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "# draw_line(plt, epoch_list, auc_score_list, 'r', label=\"auc negative - positive\", max_marker=\"^\")\n",
    "draw_line(plt, epoch_list, auc_pos_list, 'g', label=\"auc positive\", max_marker=\"^\")\n",
    "# draw_line(plt, epoch_list, auc_neg_list, 'b', label=\"auc negative\", max_marker=\"^\")\n",
    "\n",
    "\n",
    "plt.ylabel('auc')\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)\n",
    "plt.yticks(np.arange(0, 1, step=0.1))\n",
    "plt.savefig(\"aggdv2.png\", dpi=400)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0.8541178003648684\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(max(auc_pos_list))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      "tensor([10,  2,  0,  7,  4,  9,  3,  8,  1, 11,  6,  5])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "n = 12\n",
    "step = 4\n",
    "perm = torch.randperm(n)\n",
    "raw = torch.arange(0, n)\n",
    "print(raw)\n",
    "print(perm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "i = 0\n",
    "beg = i * step\n",
    "end = min(n, (i+1) * step)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 2,  2,  1,  7,  4,  5,  6,  3,  8,  9,  0, 11])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 26
    }
   ],
   "source": [
    "rand_swap_index = torch.arange(0, n)\n",
    "rand_swap_index[beg:end] = perm[beg:end]\n",
    "rand_swap_index[perm[beg:end]] = raw[beg:end]\n",
    "rand_swap_index\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "ggd",
   "language": "python",
   "display_name": "GGD"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}